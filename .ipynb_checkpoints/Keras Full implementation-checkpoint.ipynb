{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "import time\n",
    "import theano\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict\n",
    "import six.moves.cPickle as pkl\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D \n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import GRU, TimeDistributed, RepeatVector, Merge, TimeDistributedDense\n",
    "import h5py\n",
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "SEQUENCE_LENGTH = 32\n",
    "MAX_SENTENCE_LENGTH = SEQUENCE_LENGTH - 3 # 1 for image, 1 for start token, 1 for end token\n",
    "BATCH_SIZE = 20\n",
    "CNN_FEATURE_SIZE = 1000\n",
    "EMBEDDING_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_processing(dataset):\n",
    "    allwords = Counter()\n",
    "    for item in dataset:\n",
    "        for sentence in item['sentences']:\n",
    "            allwords.update(sentence['tokens'])\n",
    "            \n",
    "    vocab = [k for k, v in allwords.items() if v >= 5]\n",
    "    vocab.insert(0, '#START#')\n",
    "    vocab.append('#UNK#')\n",
    "    vocab.append('#END#')\n",
    "\n",
    "    word_to_index = {w: i for i, w in enumerate(vocab)}\n",
    "    index_to_word = {i: w for i, w in enumerate(vocab)}\n",
    "    return vocab, word_to_index, index_to_word\n",
    "\n",
    "def import_flickr8kdataset():\n",
    "    dataset = json.load(open('captions/dataset_flickr8k.json'))['images']\n",
    "    #reduced length to a 300 for testing\n",
    "    val_set = list(filter(lambda x: x['split'] == 'val', dataset))\n",
    "    train_set = list(filter(lambda x: x['split'] == 'train', dataset))\n",
    "    test_set = list(filter(lambda x: x['split'] == 'test', dataset))\n",
    "    return train_set[:800]+val_set[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def floatX(arr):\n",
    "    return np.asarray(arr, dtype=theano.config.floatX)\n",
    "\n",
    "#Prep Image uses an skimage transform\n",
    "def prep_image(im):\n",
    "    if len(im.shape) == 2:\n",
    "        im = im[:, :, np.newaxis]\n",
    "        im = np.repeat(im, 3, axis=2)\n",
    "    # Resize so smallest dim = 224, preserving aspect ratio\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (224, w*224/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*224/w, 224), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    \n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "\n",
    "    im = im - MEAN_VALUES\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language_model():\n",
    "    model = Sequential()\n",
    "    print('Adding Embedding')\n",
    "    model.add(Embedding(VOCAB_COUNT, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH-1))\n",
    "    print('Adding LSTM')\n",
    "    model.add(LSTM(EMBEDDING_SIZE, return_sequences=True))\n",
    "    print('Adding TimeDistributed Dense')\n",
    "    model.add(TimeDistributed(Dense(CNN_FEATURE_SIZE)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#START#', u'pointing', u'yellow', u'four', u'children', u'young', u'to', u'bike', u'brown', u'woman', u'sitting', u'bubbles', u'large', u'race', u'sidewalk', u'round', u'sign', u'street', u'blue', u'plays', u'stands', u'near', u'uniform', u'pose', u'men', u'water', u'baseball', u'along', u'boy', u'family', u'cheerleader', u'standing', u'from', u'camera', u'tennis', u'under', u'trail', u'carrying', u'stick', u'women', u'car', u'grassy', u'high', u'something', u'sunglasses', u'tan', u'pink', u'sit', u'beach', u'after', u'jumping', u'wave', u'man', u'a', u'green', u'playing', u'shoes', u'over', u'through', u'looks', u'smiling', u'its', u'group', u'cheerleaders', u'covered', u'runs', u'hands', u'front', u'slide', u'rock', u'side', u'catching', u'girl', u'out', u'looking', u'hill', u'red', u'dirt', u'scarf', u'one', u'another', u'city', u'little', u'toy', u'top', u'girls', u'their', u'shorts', u'white', u'dogs', u'store', u'park', u'tree', u'light', u'and', u'blond', u'mountain', u'snow', u'play', u'track', u'mouth', u'picture', u'dog', u'walking', u'outside', u'black', u'riding', u'wearing', u'his', u'trees', u'him', u'catches', u'she', u'up', u'are', u'behind', u'finger', u'across', u'guitar', u'taking', u'wall', u'walk', u'boat', u'three', u'brick', u'child', u'soccer', u'air', u'while', u'is', u'it', u'player', u'in', u'ready', u'sits', u'helmet', u'shirt', u'ball', u'snowboarder', u'hand', u'running', u'climbing', u'off', u'ocean', u'person', u'the', u'lake', u'bench', u'book', u'wet', u'has', u'hat', u'around', u'big', u'lady', u'old', u'people', u'toys', u'some', u'back', u'for', u'purple', u'jumps', u'by', u'on', u'of', u'stand', u'road', u'swimming', u'into', u'two', u'down', u'next', u'her', u'area', u'there', u'mountains', u'head', u'snowy', u'with', u'inside', u'grass', u'adults', u'an', u'as', u'at', u'walks', u'ice', u'dressed', u'field', u'other', u'holding', u'smiles', u'frisbee', u'pool', u'cliff', u'building', u'together', u'jacket', '#UNK#', '#END#']\n"
     ]
    }
   ],
   "source": [
    "dataset = import_flickr8kdataset()\n",
    "# Currently testing it out\n",
    "dataset = [i for i in dataset[:100]]\n",
    "vocab,word_to_index, index_to_word = word_processing(dataset)\n",
    "print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def process_images(dataset, coco=False, d_set=\"Flicker8k_Dataset\"):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    cnn_input = floatX(np.zeros((len(dataset), 3, 224, 224)))\n",
    "    rawim_input = []\n",
    "    sentences_tokens = []\n",
    "    for i, image in enumerate(dataset):\n",
    "        print \"ind_process %s total %s\" %(str(ind_process),str(total))\n",
    "        ind_process+=1\n",
    "        if coco:\n",
    "            fn = './coco/{}/{}'.format(image['filepath'], image['filename'])\n",
    "        else:\n",
    "            fn = d_set+'/{}'.format(image['filename'])\n",
    "        try:\n",
    "            im = plt.imread(fn)\n",
    "            rawim, cnn_input[i] = prep_image(im)\n",
    "            sentences_tokens.append(image['sentences'][0]['tokens'])\n",
    "            rawim_input.append(rawim)\n",
    "        except IOError:\n",
    "            continue\n",
    "    return rawim_input, cnn_input, sentences_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind_process 1 total 100\n",
      "ind_process 2 total 100\n",
      "ind_process 3 total 100\n",
      "ind_process 4 total 100\n",
      "ind_process 5 total 100\n",
      "ind_process 6 total 100\n",
      "ind_process 7 total 100\n",
      "ind_process 8 total 100\n",
      "ind_process 9 total 100\n",
      "ind_process 10 total 100\n",
      "ind_process 11 total 100\n",
      "ind_process 12 total 100\n",
      "ind_process 13 total 100\n",
      "ind_process 14 total 100\n",
      "ind_process 15 total 100\n",
      "ind_process 16 total 100\n",
      "ind_process 17 total 100\n",
      "ind_process 18 total 100\n",
      "ind_process 19 total 100\n",
      "ind_process 20 total 100\n",
      "ind_process 21 total 100\n",
      "ind_process 22 total 100\n",
      "ind_process 23 total 100\n",
      "ind_process 24 total 100\n",
      "ind_process 25 total 100\n",
      "ind_process 26 total 100\n",
      "ind_process 27 total 100\n",
      "ind_process 28 total 100\n",
      "ind_process 29 total 100\n",
      "ind_process 30 total 100\n",
      "ind_process 31 total 100\n",
      "ind_process 32 total 100\n",
      "ind_process 33 total 100\n",
      "ind_process 34 total 100\n",
      "ind_process 35 total 100\n",
      "ind_process 36 total 100\n",
      "ind_process 37 total 100\n",
      "ind_process 38 total 100\n",
      "ind_process 39 total 100\n",
      "ind_process 40 total 100\n",
      "ind_process 41 total 100\n",
      "ind_process 42 total 100\n",
      "ind_process 43 total 100\n",
      "ind_process 44 total 100\n",
      "ind_process 45 total 100\n",
      "ind_process 46 total 100\n",
      "ind_process 47 total 100\n",
      "ind_process 48 total 100\n",
      "ind_process 49 total 100\n",
      "ind_process 50 total 100\n",
      "ind_process 51 total 100\n",
      "ind_process 52 total 100\n",
      "ind_process 53 total 100\n",
      "ind_process 54 total 100\n",
      "ind_process 55 total 100\n",
      "ind_process 56 total 100\n",
      "ind_process 57 total 100\n",
      "ind_process 58 total 100\n",
      "ind_process 59 total 100\n",
      "ind_process 60 total 100\n",
      "ind_process 61 total 100\n",
      "ind_process 62 total 100\n",
      "ind_process 63 total 100\n",
      "ind_process 64 total 100\n",
      "ind_process 65 total 100\n",
      "ind_process 66 total 100\n",
      "ind_process 67 total 100\n",
      "ind_process 68 total 100\n",
      "ind_process 69 total 100\n",
      "ind_process 70 total 100\n",
      "ind_process 71 total 100\n",
      "ind_process 72 total 100\n",
      "ind_process 73 total 100\n",
      "ind_process 74 total 100\n",
      "ind_process 75 total 100\n",
      "ind_process 76 total 100\n",
      "ind_process 77 total 100\n",
      "ind_process 78 total 100\n",
      "ind_process 79 total 100\n",
      "ind_process 80 total 100\n",
      "ind_process 81 total 100\n",
      "ind_process 82 total 100\n",
      "ind_process 83 total 100\n",
      "ind_process 84 total 100\n",
      "ind_process 85 total 100\n",
      "ind_process 86 total 100\n",
      "ind_process 87 total 100\n",
      "ind_process 88 total 100\n",
      "ind_process 89 total 100\n",
      "ind_process 90 total 100\n",
      "ind_process 91 total 100\n",
      "ind_process 92 total 100\n",
      "ind_process 93 total 100\n",
      "ind_process 94 total 100\n",
      "ind_process 95 total 100\n",
      "ind_process 96 total 100\n",
      "ind_process 97 total 100\n",
      "ind_process 98 total 100\n",
      "ind_process 99 total 100\n",
      "ind_process 100 total 100\n"
     ]
    }
   ],
   "source": [
    "rawim_array, cnnim_array, sentences_tokens = process_images(dataset, coco=False, d_set=\"Flicker8k_Dataset\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_image_partial_captions(images, captions, word_to_index, vocab_count):\n",
    "    a_images = []\n",
    "    a_captions = []\n",
    "    next_words = []\n",
    "    #vocab_size = len(vocab)\n",
    "    for ind, image in enumerate(images):\n",
    "        sentence = captions[ind]\n",
    "        partial_caption_ar = np.zeros(SEQUENCE_LENGTH-1, dtype=np.int)\n",
    "        \n",
    "        words = ['#START#'] + sentence + ['#END#']\n",
    "        assert len(words)<SEQUENCE_LENGTH\n",
    "        for i in range(len(words) - 1):\n",
    "            pc_copy = partial_caption_ar.copy()\n",
    "            if words[i] in word_to_index:\n",
    "                pc_copy[i] = word_to_index[words[i]]\n",
    "            else:\n",
    "                pc_copy[i] = word_to_index[\"#UNK#\"]\n",
    "            a_images.append(image)\n",
    "            a_captions.append(pc_copy)\n",
    "            #Generate next word output vector\n",
    "            next_word = words[i + 1]\n",
    "            if next_word in word_to_index:\n",
    "                next_word_index = word_to_index[next_word]\n",
    "            else:\n",
    "                next_word_index = word_to_index[\"#UNK#\"]\n",
    "            next_word_ar = np.zeros(vocab_count, dtype=np.int)\n",
    "            next_word_ar[next_word_index] = 1\n",
    "            next_words.append(next_word_ar)\n",
    "    v_i = np.array(a_images)\n",
    "    v_c = np.array(a_captions)\n",
    "    v_nw = np.array(next_words)\n",
    "    return v_i, v_c, v_nw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "vocab_count = len(word_to_index)\n",
    "print cnnim_array.shape\n",
    "v_i, v_c, v_nw = gen_image_partial_captions(cnnim_array, sentences_tokens, word_to_index, vocab_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_COUNT = len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(weights_path):\n",
    "    image_model = VGG_16(weights_path)\n",
    "    image_model.add(RepeatVector(SEQUENCE_LENGTH-1))\n",
    "    print('Built Image Model')\n",
    "    print('Building Language Model')\n",
    "    lang_model = language_model()\n",
    "    model = Sequential()\n",
    "    model.add(Merge([image_model, lang_model], mode='concat',  concat_axis=-1))\n",
    "    model.add(LSTM(EMBEDDING_SIZE, return_sequences=False))\n",
    "    #print(vocab_size)\n",
    "    model.add(Dense(VOCAB_COUNT, activation='softmax'))\n",
    "\n",
    "    #print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built Image Model\n",
      "Building Language Model\n",
      "Adding Embedding\n",
      "Adding LSTM\n",
      "Adding TimeDistributed Dense\n",
      "Built model.\n",
      "Compiling Now\n",
      "Fitting Now\n",
      "Epoch 1/1\n",
      "  30/1274 [..............................] - ETA: 2805s - loss: 5.1810 - acc: 0.0333"
     ]
    }
   ],
   "source": [
    "model=build_model('weights/vgg16_weights.h5')\n",
    "print('Built model.')\n",
    "print('Compiling Now')\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print('Fitting Now')\n",
    "model.fit([v_i, v_c], v_nw, batch_size=3, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, images, index_to_word, word_to_index):\n",
    "    for image in images:\n",
    "        caption = np.zeros(SEQUENCE_LENGTH - 1).reshape(1, SEQUENCE_LENGTH - 1)\n",
    "        print(caption.shape)\n",
    "        caption[0,0] = 0\n",
    "        count=0\n",
    "        sentence = []\n",
    "        a = image.reshape(1,3,224,224)\n",
    "        #a = np.array([image])\n",
    "        while True:\n",
    "            out = model.predict([a, caption])\n",
    "            index = out.argmax(-1)\n",
    "            index = index[0]\n",
    "            word = index_to_word[index]\n",
    "            sentence.append(word)\n",
    "            count+= 1\n",
    "            if count >= SEQUENCE_LENGTH - 1 or index == word_to_index[\"#END#\"]: #max caption length reach of '<eos>' encountered\n",
    "                break\n",
    "            caption[0,count] = index\n",
    "        sent_str = \" \".join(sentence)\n",
    "        print(\"The Oracle says : %s\" %sent_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnim_list = []\n",
    "for i in cnnim_array:\n",
    "    cnnim_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict(model, cnnim_list, index_to_word, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes exactly 4 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-fa959c14067b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnnim_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_to_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict() takes exactly 4 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "predict(model, cnnim_list, index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n",
      "(3, 224, 224)\n",
      "[[ 0.01479965  0.02197597  0.1271223   0.0757821   0.11408521  0.02933407\n",
      "   0.02511705  0.06509422  0.47890654  0.04778289]\n",
      " [ 0.01412566  0.02101637  0.13756378  0.06709128  0.09927694  0.03693941\n",
      "   0.02461312  0.06562667  0.4821761   0.05157067]\n",
      " [ 0.01461078  0.02260523  0.13023429  0.07412055  0.10645258  0.03562364\n",
      "   0.02546796  0.06531136  0.47494298  0.05063061]\n",
      " [ 0.01535605  0.02531418  0.12274525  0.08307311  0.11395948  0.03609204\n",
      "   0.02680946  0.06548851  0.46061364  0.05054829]\n",
      " [ 0.01574896  0.02529401  0.11877078  0.08701741  0.12167319  0.0309793\n",
      "   0.02692072  0.06540363  0.45984092  0.04835107]\n",
      " [ 0.01577112  0.0246546   0.11802998  0.0869009   0.12414648  0.02843006\n",
      "   0.02665788  0.06534739  0.46276993  0.04729164]\n",
      " [ 0.01573384  0.02382465  0.11917216  0.08517403  0.12476258  0.02666877\n",
      "   0.02624967  0.0654726   0.46632922  0.04661248]\n",
      " [ 0.01556872  0.02274938  0.12185793  0.08195729  0.12369877  0.02534524\n",
      "   0.02561617  0.06581294  0.47117496  0.04621858]\n",
      " [ 0.01517017  0.02166727  0.12576906  0.07730211  0.118615    0.0261247\n",
      "   0.02502081  0.06546894  0.47820199  0.04665995]\n",
      " [ 0.0148854   0.02058269  0.13075683  0.07214792  0.11444799  0.0263476\n",
      "   0.02435931  0.06531833  0.48420313  0.04695081]\n",
      " [ 0.01445347  0.02007199  0.13442594  0.06869812  0.10877642  0.02873406\n",
      "   0.02405833  0.06503042  0.48769739  0.04805386]\n",
      " [ 0.01440821  0.0202087   0.13529086  0.06821318  0.10717526  0.03014097\n",
      "   0.02413306  0.06490556  0.48687279  0.0486514 ]\n",
      " [ 0.01443272  0.02091782  0.13268557  0.07023147  0.10848494  0.03096285\n",
      "   0.02452002  0.06462998  0.48450193  0.04863271]\n",
      " [ 0.01479965  0.02197597  0.1271223   0.0757821   0.11408521  0.02933407\n",
      "   0.02511705  0.06509422  0.47890654  0.04778289]\n",
      " [ 0.01412566  0.02101637  0.13756378  0.06709128  0.09927694  0.03693941\n",
      "   0.02461312  0.06562667  0.4821761   0.05157067]\n",
      " [ 0.01461078  0.02260523  0.13023429  0.07412055  0.10645258  0.03562364\n",
      "   0.02546796  0.06531136  0.47494298  0.05063061]\n",
      " [ 0.0151211   0.02409222  0.12387498  0.08083586  0.11361831  0.03386067\n",
      "   0.02625444  0.06525868  0.46741059  0.04967315]\n",
      " [ 0.01555367  0.02482309  0.11951675  0.08553156  0.12018014  0.03106045\n",
      "   0.02668444  0.06525692  0.46298698  0.048406  ]\n",
      " [ 0.01577112  0.0246546   0.11802998  0.0869009   0.12414648  0.02843006\n",
      "   0.02665788  0.06534739  0.46276993  0.04729164]\n",
      " [ 0.01479965  0.02197597  0.1271223   0.0757821   0.11408521  0.02933407\n",
      "   0.02511705  0.06509422  0.47890654  0.04778289]\n",
      " [ 0.01412566  0.02101637  0.13756378  0.06709128  0.09927694  0.03693941\n",
      "   0.02461312  0.06562667  0.4821761   0.05157067]\n",
      " [ 0.01461078  0.02260523  0.13023429  0.07412055  0.10645258  0.03562364\n",
      "   0.02546796  0.06531136  0.47494298  0.05063061]\n",
      " [ 0.01535605  0.02531418  0.12274525  0.08307311  0.11395948  0.03609204\n",
      "   0.02680946  0.06548851  0.46061364  0.05054829]\n",
      " [ 0.01594489  0.02603803  0.11636028  0.08988811  0.1242163   0.03077084\n",
      "   0.02735677  0.06550908  0.4556742   0.04824151]\n",
      " [ 0.01615961  0.02580759  0.11544596  0.09070618  0.12752458  0.02839847\n",
      "   0.02731273  0.06557245  0.45578867  0.04728374]\n",
      " [ 0.01575553  0.02409711  0.11912054  0.08535247  0.12492053  0.02711285\n",
      "   0.0263692   0.06547547  0.46501407  0.04678222]\n",
      " [ 0.01549934  0.02271778  0.1220884   0.08152976  0.12252415  0.0259371\n",
      "   0.0256399   0.0655327   0.47210294  0.04642793]\n",
      " [ 0.01517017  0.02166727  0.12576906  0.07730211  0.118615    0.0261247\n",
      "   0.02502081  0.06546894  0.47820199  0.04665995]\n",
      " [ 0.01484506  0.02089209  0.12927994  0.07356304  0.11432955  0.02702904\n",
      "   0.02454017  0.06529164  0.48305771  0.04717178]\n",
      " [ 0.01463499  0.02046174  0.13302124  0.07021917  0.11046855  0.02859575\n",
      "   0.02430623  0.06491512  0.4854984   0.04787882]\n",
      " [ 0.01431708  0.02025769  0.13528731  0.0680078   0.10653008  0.03071762\n",
      "   0.02414313  0.06469902  0.48727369  0.04876658]\n",
      " [ 0.01445917  0.02098179  0.13217159  0.07087249  0.10829753  0.03118391\n",
      "   0.02448572  0.06461401  0.48418054  0.04875325]\n",
      " [ 0.01457088  0.02165737  0.1300444   0.07298679  0.10976193  0.0318187\n",
      "   0.02483737  0.0644673   0.48105165  0.04880362]]\n"
     ]
    }
   ],
   "source": [
    "caption = np.zeros(SEQUENCE_LENGTH).reshape(1, SEQUENCE_LENGTH)\n",
    "caption[0] = word_to_index[\"#START#\"]\n",
    "print cnnim_array[0].shape\n",
    "t = np.array(cnnim_array[0])\n",
    "print t.shape\n",
    "out = model.predict([v_i, v_c])\n",
    "print out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 10)\n",
      "{u'filename': u'2513260012_03d33305cf.jpg', u'imgid': 0, u'sentences': [{u'tokens': [u'a', u'black', u'dog', u'is', u'running', u'after', u'a', u'white', u'dog', u'in', u'the', u'snow'], u'raw': u'A black dog is running after a white dog in the snow .', u'imgid': 0, u'sentid': 0}, {u'tokens': [u'black', u'dog', u'chasing', u'brown', u'dog', u'through', u'snow'], u'raw': u'Black dog chasing brown dog through snow', u'imgid': 0, u'sentid': 1}, {u'tokens': [u'two', u'dogs', u'chase', u'each', u'other', u'across', u'the', u'snowy', u'ground'], u'raw': u'Two dogs chase each other across the snowy ground .', u'imgid': 0, u'sentid': 2}, {u'tokens': [u'two', u'dogs', u'play', u'together', u'in', u'the', u'snow'], u'raw': u'Two dogs play together in the snow .', u'imgid': 0, u'sentid': 3}, {u'tokens': [u'two', u'dogs', u'running', u'through', u'a', u'low', u'lying', u'body', u'of', u'water'], u'raw': u'Two dogs running through a low lying body of water .', u'imgid': 0, u'sentid': 4}], u'split': u'train', u'sentids': [0, 1, 2, 3, 4]}\n"
     ]
    }
   ],
   "source": [
    "print out.shape\n",
    "print dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "zeropadding2d_209 (ZeroPadding2D)(None, 3, 226, 226)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_209 (Convolution2D)(None, 64, 224, 224)  1792                                         \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_210 (ZeroPadding2D)(None, 64, 226, 226)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_210 (Convolution2D)(None, 64, 224, 224)  36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_81 (MaxPooling2D)   (None, 64, 112, 112)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_211 (ZeroPadding2D)(None, 64, 114, 114)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_211 (Convolution2D)(None, 128, 112, 112) 73856                                        \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_212 (ZeroPadding2D)(None, 128, 114, 114) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_212 (Convolution2D)(None, 128, 112, 112) 147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_82 (MaxPooling2D)   (None, 128, 56, 56)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_213 (ZeroPadding2D)(None, 128, 58, 58)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_213 (Convolution2D)(None, 256, 56, 56)   295168                                       \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_214 (ZeroPadding2D)(None, 256, 58, 58)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_214 (Convolution2D)(None, 256, 56, 56)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_215 (ZeroPadding2D)(None, 256, 58, 58)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_215 (Convolution2D)(None, 256, 56, 56)   590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_83 (MaxPooling2D)   (None, 256, 28, 28)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_216 (ZeroPadding2D)(None, 256, 30, 30)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_216 (Convolution2D)(None, 512, 28, 28)   1180160                                      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_217 (ZeroPadding2D)(None, 512, 30, 30)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_217 (Convolution2D)(None, 512, 28, 28)   2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_218 (ZeroPadding2D)(None, 512, 30, 30)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_218 (Convolution2D)(None, 512, 28, 28)   2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_84 (MaxPooling2D)   (None, 512, 14, 14)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_219 (ZeroPadding2D)(None, 512, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_219 (Convolution2D)(None, 512, 14, 14)   2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_220 (ZeroPadding2D)(None, 512, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_220 (Convolution2D)(None, 512, 14, 14)   2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_221 (ZeroPadding2D)(None, 512, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_221 (Convolution2D)(None, 512, 14, 14)   2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_85 (MaxPooling2D)   (None, 512, 7, 7)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 25088)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 4096)          102764544                                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)             (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 4096)          16781312                                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)             (None, 4096)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_58 (Dense)                 (None, 1000)          4097000                                      \n",
      "____________________________________________________________________________________________________\n",
      "repeatvector_14 (RepeatVector)   (None, 31, 1000)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)          (None, 31, 256)       2560                                         \n",
      "____________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                    (None, 31, 1000)      5028000                                      \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_5 (TimeDistribute(None, 31, 1000)      1001000                                      \n",
      "____________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                    (None, 256)           2311168     merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_60 (Dense)                 (None, 10)            2570        lstm_9[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 146702842\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
