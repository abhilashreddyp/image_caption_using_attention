{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "import time\n",
    "import theano\n",
    "import keras\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict\n",
    "import six.moves.cPickle as pkl\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, LSTM, Lambda, merge\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D \n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import GRU, TimeDistributed, RepeatVector, Merge, TimeDistributedDense\n",
    "import h5py\n",
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from attention_lstm import AttentionLSTM\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback\n",
    "#import theano.tensor as T\n",
    "#import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "SEQUENCE_LENGTH = 45\n",
    "MAX_SENTENCE_LENGTH = SEQUENCE_LENGTH - 3 # 1 for image, 1 for start token, 1 for end token\n",
    "BATCH_SIZE = 20\n",
    "OUTPUT_DIM = 512\n",
    "ANNOTATION_DIM = 512\n",
    "WORD_DIM = 512\n",
    "ANNOTATION_SIZE=196\n",
    "ANNOTION_LENGTH = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "with open('features/flickr30kann_1000_p3.pkl', 'rb') as f:\n",
    "    d = pkl.load(f)\n",
    "#pkl.dump(d, open('features/flickr30kann_1000_p3.pkl', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "vocab = d['vocab']\n",
    "word_to_index = d['word_to_index']\n",
    "index_to_word = d['index_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 44, 2452)\n",
      "(1000, 44, 2452)\n",
      "(1000, 196, 512)\n",
      "(1000, 512)\n"
     ]
    }
   ],
   "source": [
    "ins = d['INS']\n",
    "gts = d['GTS']\n",
    "ann_vec = d['AnnotationVectors']\n",
    "ann_vec = ann_vec.reshape(1000,196,512)\n",
    "z_mean = np.mean(ann_vec, axis=1)\n",
    "print(ins.shape)\n",
    "print(gts.shape)\n",
    "print(ann_vec.shape)\n",
    "print(z_mean.shape)\n",
    "VOCAB_COUNT = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 44, 2452)\n",
      "(100, 44, 2452)\n",
      "(900, 512)\n",
      "(100, 44, 2452)\n",
      "(900, 196, 512)\n"
     ]
    }
   ],
   "source": [
    "ins_train = ins[0:900, :, :]\n",
    "gts_train = gts[0:900, :, :]\n",
    "ann_vec_train = ann_vec[0:900, :, :]\n",
    "z_mean_train = z_mean[0:900, :]\n",
    "\n",
    "ins_test = ins[900:, :, :]\n",
    "gts_test = gts[900:, :, :]\n",
    "ann_vec_test = ann_vec[900:, :, :]\n",
    "z_mean_test = z_mean[900:, :]\n",
    "\n",
    "x_train = [ins_train, ann_vec_train, z_mean_train]\n",
    "x_test = [ins_test, ann_vec_test, z_mean_test]\n",
    "\n",
    "y_train = gts_train\n",
    "y_test = gts_test\n",
    "print(ins_train.shape)\n",
    "print(ins_test.shape)\n",
    "print(z_mean_train.shape)\n",
    "print(gts_test.shape)\n",
    "print(ann_vec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model\n",
      "Softmax.0\n",
      "Softmax.0\n",
      "input shapes [(None, 44, 512), (None, 512), (None, 512), (None, 196, 512)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\nprint('Adding Embedding')\\nmodel.add(Embedding(VOCAB_COUNT, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH-1))\\nprint('Adding LSTM')\\nmodel.add(AttentionLSTM(EMBEDDING_SIZE, Z_DIM, return_sequences=True))\\nprint('Adding TimeDistributed Dense')\\nmodel.add(TimeDistributed(Dense(EMBEDDING_SIZE)))\\nreturn model\\nmodel.add(Dense(VOCAB_COUNT, activation='softmax'))\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aLstm_Layer = None\n",
    "\n",
    "print('Building Model')\n",
    "x_inp = Input(shape=(SEQUENCE_LENGTH-1, VOCAB_COUNT))\n",
    "z_inp = Input(shape=(ANNOTATION_SIZE, ANNOTATION_DIM,))\n",
    "z_mean = Input(shape=(ANNOTATION_DIM,))\n",
    "h_Dense_l = Dense(OUTPUT_DIM, input_dim=ANNOTATION_DIM, activation='softmax')\n",
    "h_Dense = h_Dense_l(z_mean)\n",
    "c_Dense = Dense(OUTPUT_DIM, input_dim=ANNOTATION_DIM, activation='softmax')(z_mean)\n",
    "#emb = Embedding(VOCAB_COUNT, WORD_DIM, input_length=SEQUENCE_LENGTH-1)(x_inp)\n",
    "#tdemb = TimeDistributed()(emb)\n",
    "xt_dense = TimeDistributed(Dense(WORD_DIM))(x_inp)\n",
    "print(h_Dense)\n",
    "print(c_Dense)\n",
    "#print(tdemb)\n",
    "#merge1 = merge([emb, h_Dense, c_Dense, z_inp], mode='concat', concat_axis=-1)\n",
    "#global aLstm_Layer\n",
    "aLstm_Layer = AttentionLSTM( output_dim=WORD_DIM, z_dim=ANNOTATION_DIM, W_regularizer=l2(0.01), U_regularizer=l2(0.01), Z_regularizer=l2(0.01), dropout_W=0.3, dropout_U=0.3, dropout_Z=0.3, return_sequences=True)\n",
    "aLstm = aLstm_Layer([xt_dense, h_Dense, c_Dense, z_inp])\n",
    "#aLstm_Alpha_Layer = AttentionLSTM(ret_alpha=True, output_dim=ANNOTION_LENGTH, z_dim=ANNOTATION_DIM, W_regularizer=l2(0.01), U_regularizer=l2(0.01), Z_regularizer=l2(0.01), dropout_W=0.3, dropout_U=0.3, dropout_Z=0.3, return_sequences=True)\n",
    "#aLstm_Alpha = aLstm_Alpha_Layer([xt_dense, h_Dense, c_Dense, z_inp])\n",
    "tdense = TimeDistributed(Dense(VOCAB_COUNT))(aLstm)\n",
    "act = Activation('softmax')(tdense)\n",
    "model = Model(input=[x_inp, z_inp, z_mean], output=act)\n",
    "'''\n",
    "model = Sequential()\n",
    "print('Adding Embedding')\n",
    "model.add(Embedding(VOCAB_COUNT, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH-1))\n",
    "print('Adding LSTM')\n",
    "model.add(AttentionLSTM(EMBEDDING_SIZE, Z_DIM, return_sequences=True))\n",
    "print('Adding TimeDistributed Dense')\n",
    "model.add(TimeDistributed(Dense(EMBEDDING_SIZE)))\n",
    "return model\n",
    "model.add(Dense(VOCAB_COUNT, activation='softmax'))\n",
    "'''\n",
    "#print(model.summary())\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AlphaCallback(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.alphaz = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.alphaz.append(K.get_value(aLstm_Layer.states[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 44, 2452)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           262656      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 512)           262656      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 196, 512)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribute(None, 44, 512)       1255936     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attentionlstm_1 (AttentionLSTM)  (None, 44, 512)       3677185     timedistributed_1[0][0]          \n",
      "                                                                   dense_1[0][0]                    \n",
      "                                                                   dense_2[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribute(None, 44, 2452)      1257876     attentionlstm_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 44, 2452)      0           timedistributed_2[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 6716309\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model = build_model()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "900/900 [==============================] - 840s - loss: 3.6165 - acc: 0.6325   \n"
     ]
    }
   ],
   "source": [
    "#print(keras.__version__)\n",
    "#alphac = AlphaCallback()\n",
    "his = model.fit(x_train, y_train, batch_size=1, nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'theano.tensor.var.TensorVariable'>\n"
     ]
    }
   ],
   "source": [
    "print(type(z_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_h1 = K.dot(z_mean, h_Dense_l.W) + h_Dense_l.b\n",
    "proj_z = K.dot(z_inp, aLstm_Layer.Wc_att) + aLstm_Layer.b_att\n",
    "proj_state = K.dot(prev_h1, aLstm_Layer.Wd_att)\n",
    "proj_z = proj_z + proj_state[:, None, :]\n",
    "proj_z = K.tanh(proj_z)\n",
    "\n",
    "alpha = K.dot(proj_z, aLstm_Layer.U_att ) + aLstm_Layer.b2_att\n",
    "alpha_shape = alpha.shape\n",
    "alpha = K.softmax(alpha.reshape((alpha_shape[0], alpha_shape[1])))\n",
    "\n",
    "f_alpha = K.function([z_inp, z_mean], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 196)\n"
     ]
    }
   ],
   "source": [
    "#alpha = f_alpha([ann_vec_train[0, :, :].reshape(1,196,512), z_mean_train[0,:].reshape(1, 512)])\n",
    "#print(type(ins))\n",
    "#al = alpha_func(x_train)\n",
    "#print(al.shape)\n",
    "#print(al)\n",
    "print(alpha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuCAReduce{add}{0,0,1}.0, <CudaNdarrayType(float32, matrix)>)\nToposort index: 118\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(3, 196), (1, 196)]\nInputs strides: [(196, 1), (0, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{0,x,1,x}(GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{44}, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{tanh,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, attentionlstm_1_U_o, attentionlstm_1_Z_o, attentionlstm_1_U_f, attentionlstm_1_Z_f, attentionlstm_1_U_i, attentionlstm_1_Z_i, attentionlstm_1_U_c, attentionlstm_1_Z_c, GpuFromHost.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, MakeVector{dtype='int64'}.0, MakeVector{dtype='int64'}.0, attentionlstm_1_U_att, GpuDimShuffle{1,0}.0)\nToposort index: 325\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, (True, True, False)), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, vector), TensorType(int64, vector), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(), (44, 3, 196, 512), (44, 3, 512), (44, 3, 512), (44, 3, 2048), (44, 1, 196), (44, 3, 196, 512), (44, 3, 512), (44, 3, 2048), (44, 3, 512), (44, 3, 512), (45, 3, 512), (45, 3, 512), (45, 3, 196, 512), (45, 1, 196), (2, 512), (2, 512, 1), (2, 1), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (), (), (), (), (), (), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (3, 196, 512), (1, 512), (512, 512), (3, 512), (1, 1, 1), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (512, 512), (2,), (1,), (512, 1), (1, 512)]\nInputs strides: [(), (-301056, 100352, 512, 1), (-1536, 512, 1), (1536, 512, 1), (6144, 2048, 1), (196, 0, 1), (301056, 100352, 512, 1), (1536, 512, 1), (-2048, 90112, 1), (-1536, 512, 1), (-512, 22528, 1), (1536, 512, 1), (1536, 512, 1), (301056, 100352, 512, 1), (196, 0, 1), (512, 1), (512, 1, 0), (1, 0), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (), (), (), (), (), (), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (100352, 512, 1), (0, 1), (1, 512), (512, 1), (0, 0, 0), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (1, 512), (8,), (8,), (1, 0), (0, 1)]\nInputs values: [array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[ 0.]\\n [ 0.]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[[ 0.]]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array([512,   1], dtype=int64), array([1], dtype=int64), 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.0, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.1, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.2, Constant{44}, Constant{43}, Constant{-1})], [], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.4, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.5, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.6, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.7, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.8, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.9, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.10, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.11, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.12, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.13, Constant{1})], [GpuSubtensor{::int64}(forall_inplace,gpu,grad_of_scan_fn}.14, Constant{-1})], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.15)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.16, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.17)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.18, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.19)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.20, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.21)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.22, MakeVector{dtype='int64'}.0)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.23, MakeVector{dtype='int64'}.0), Shape_i{1}(forall_inplace,gpu,grad_of_scan_fn}.23), Shape_i{2}(forall_inplace,gpu,grad_of_scan_fn}.23)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    954\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    943\u001b[0m                                          \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                                          self, node)\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4316)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuCAReduce{add}{0,0,1}.0, <CudaNdarrayType(float32, matrix)>)\nToposort index: 118\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(3, 196), (1, 196)]\nInputs strides: [(196, 1), (0, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{0,x,1,x}(GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f5c6dd8673d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    953\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    954\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    942\u001b[0m                                          \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                                          \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                                          self, node)\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4316)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuCAReduce{add}{0,0,1}.0, <CudaNdarrayType(float32, matrix)>)\nToposort index: 118\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(3, 196), (1, 196)]\nInputs strides: [(196, 1), (0, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{0,x,1,x}(GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{44}, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{tanh,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, attentionlstm_1_U_o, attentionlstm_1_Z_o, attentionlstm_1_U_f, attentionlstm_1_Z_f, attentionlstm_1_U_i, attentionlstm_1_Z_i, attentionlstm_1_U_c, attentionlstm_1_Z_c, GpuFromHost.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, MakeVector{dtype='int64'}.0, MakeVector{dtype='int64'}.0, attentionlstm_1_U_att, GpuDimShuffle{1,0}.0)\nToposort index: 325\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, (True, True, False)), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, vector), TensorType(int64, vector), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(), (44, 3, 196, 512), (44, 3, 512), (44, 3, 512), (44, 3, 2048), (44, 1, 196), (44, 3, 196, 512), (44, 3, 512), (44, 3, 2048), (44, 3, 512), (44, 3, 512), (45, 3, 512), (45, 3, 512), (45, 3, 196, 512), (45, 1, 196), (2, 512), (2, 512, 1), (2, 1), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (), (), (), (), (), (), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (3, 196, 512), (1, 512), (512, 512), (3, 512), (1, 1, 1), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (512, 512), (2,), (1,), (512, 1), (1, 512)]\nInputs strides: [(), (-301056, 100352, 512, 1), (-1536, 512, 1), (1536, 512, 1), (6144, 2048, 1), (196, 0, 1), (301056, 100352, 512, 1), (1536, 512, 1), (-2048, 90112, 1), (-1536, 512, 1), (-512, 22528, 1), (1536, 512, 1), (1536, 512, 1), (301056, 100352, 512, 1), (196, 0, 1), (512, 1), (512, 1, 0), (1, 0), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (), (), (), (), (), (), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (100352, 512, 1), (0, 1), (1, 512), (512, 1), (0, 0, 0), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (1, 512), (8,), (8,), (1, 0), (0, 1)]\nInputs values: [array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[ 0.]\\n [ 0.]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[[ 0.]]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array([512,   1], dtype=int64), array([1], dtype=int64), 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.0, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.1, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.2, Constant{44}, Constant{43}, Constant{-1})], [], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.4, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.5, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.6, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.7, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.8, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.9, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.10, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.11, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.12, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.13, Constant{1})], [GpuSubtensor{::int64}(forall_inplace,gpu,grad_of_scan_fn}.14, Constant{-1})], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.15)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.16, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.17)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.18, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.19)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.20, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.21)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.22, MakeVector{dtype='int64'}.0)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.23, MakeVector{dtype='int64'}.0), Shape_i{1}(forall_inplace,gpu,grad_of_scan_fn}.23), Shape_i{2}(forall_inplace,gpu,grad_of_scan_fn}.23)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=3, nb_epoch=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(x_test, y_test, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3651199567317964, 0.67022727072238919]\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 22s    \n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict(x_train, batch_size=3, verbose=1)\n",
    "y_pred_test = model.predict([ins, ann_vec, z_mean], batch_size=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 44, 2452)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "\n",
    "def gen_captions(y_p):\n",
    "    sentences = []\n",
    "    for y_i in y_p:\n",
    "        sentence = \"\"\n",
    "        for word_v in y_i:\n",
    "            max_i = np.argmax(word_v, axis = -1)\n",
    "            word = index_to_word[max_i]\n",
    "            if word == '#END#' or word == '#NULL#':\n",
    "                break\n",
    "            sentence = sentence + word + \" \"\n",
    "        #print(sentence)\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gts_sentences = gen_captions(gts)\n",
    "gts_train = gts_sentences[1:900]\n",
    "gts_test = gts_sentences[900:]\n",
    "\n",
    "def create_json_dict(s_train):\n",
    "    s_d = []\n",
    "    for i, sent in enumerate(s_train):\n",
    "        dict_cap = {}\n",
    "        dict_cap[\"image_id\"] = i\n",
    "        dict_cap[\"caption\"] = sent\n",
    "        s_d.append(dict_cap)\n",
    "    return s_d\n",
    "\n",
    "train_d = create_json_dict(gts_train)\n",
    "test_d = create_json_dict(gts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_full = create_json_dict(gts_sentences)\n",
    "pred_sent_full = gen_captions(y_pred_test)\n",
    "pred_full = create_json_dict(pred_sent_full)\n",
    "\n",
    "with open('results/attn_pred.json', 'w') as f:\n",
    "    json.dump(pred_full, f)\n",
    "    \n",
    "with open('results/attn_ref.json', 'w') as f:\n",
    "    json.dump(train_full, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899\n",
      "899\n",
      "899\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "pred_sentence = []\n",
    "pred_sentence = gen_captions(y_pred)\n",
    "pred_d = create_json_dict(pred_sentence)\n",
    "print(len(pred_sentence))\n",
    "print(len(pred_d))\n",
    "print(len(y_pred))\n",
    "\n",
    "pred_test_sentence = []\n",
    "pred_test_sentence = gen_captions(y_pred_test)\n",
    "pred_d_test = create_json_dict(pred_test_sentence)\n",
    "print(len(pred_test_sentence))\n",
    "print(len(pred_d_test))\n",
    "print(len(y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train, batch_size=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('results/ref_train.json', 'w') as f:\n",
    "    json.dump(train_d, f)\n",
    "\n",
    "with open('results/ref_test.json', 'w') as f:\n",
    "    json.dump(test_d, f)\n",
    "\n",
    "with open('results/pred_train.json', 'w') as f:\n",
    "    json.dump(pred_d, f)\n",
    "\n",
    "with open('results/pred_test.json', 'w') as f:\n",
    "    json.dump(pred_d_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = []\n",
    "with open('results/VGG16_LTSM_1k.pkl', 'rb') as f: \n",
    "    j = pkl.load(f, encoding='latin1')\n",
    "\n",
    "def gen_json_dict_from_pkl(pkl_list):\n",
    "    pred_list = []\n",
    "    ref_list = []\n",
    "    for i, pkl_dict in enumerate(pkl_list):\n",
    "        dict_cap = {}\n",
    "        dict_cap ['image_id'] = i\n",
    "        dict_cap['caption'] = pkl_dict['predictions'][0]\n",
    "        pred_list.append(dict_cap)\n",
    "        dict_ref = {}\n",
    "        dict_ref['image_id'] = i\n",
    "        dict_ref['caption'] = pkl_dict['labels'][0]\n",
    "        ref_list.append(dict_ref)\n",
    "    return pred_list, ref_list\n",
    "\n",
    "gnet_pred, gnet_ref = gen_json_dict_from_pkl(j)\n",
    "with open('results/VGG16_LTSM_1k_pred.json', 'w') as f:\n",
    "    json.dump(gnet_pred, f)\n",
    "\n",
    "with open('results/VGG16_LTSM_1k_ref.json', 'w') as f:\n",
    "    json.dump(gnet_ref, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_processing(dataset):\n",
    "    allwords = Counter()\n",
    "    for item in dataset:\n",
    "        for sentence in item['sentences']:\n",
    "            allwords.update(sentence['tokens'])\n",
    "            \n",
    "    vocab = [k for k, v in allwords.items()]\n",
    "    vocab.insert(0, '<NULL>')\n",
    "    vocab.append('<START>')\n",
    "    vocab.append('<END>')\n",
    "    vocab.append('<UNK>')\n",
    "\n",
    "    word_to_index = {w: i for i, w in enumerate(vocab)}\n",
    "    index_to_word = {i: w for i, w in enumerate(vocab)}\n",
    "    return vocab, word_to_index, index_to_word\n",
    "\n",
    "def import_flickr8kdataset():\n",
    "    dataset = json.load(open('captions/dataset_flickr8k.json'))['images']\n",
    "    #reduced length to a 300 for testing\n",
    "    val_set = list(filter(lambda x: x['split'] == 'val', dataset))\n",
    "    train_set = list(filter(lambda x: x['split'] == 'train', dataset))\n",
    "    test_set = list(filter(lambda x: x['split'] == 'test', dataset))\n",
    "    return train_set[:800]+val_set[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def floatX(arr):\n",
    "    return np.asarray(arr, dtype=theano.config.floatX)\n",
    "\n",
    "#Prep Image uses an skimage transform\n",
    "def prep_image(im):\n",
    "    if len(im.shape) == 2:\n",
    "        im = im[:, :, np.newaxis]\n",
    "        im = np.repeat(im, 3, axis=2)\n",
    "    # Resize so smallest dim = 224, preserving aspect ratio\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (224, w*224/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*224/w, 224), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    \n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "\n",
    "    im = im - MEAN_VALUES\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language_model():\n",
    "    model = Sequential()\n",
    "    print('Adding Embedding')\n",
    "    model.add(Embedding(VOCAB_COUNT, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH-1))\n",
    "    print('Adding LSTM')\n",
    "    model.add(LSTM(EMBEDDING_SIZE, return_sequences=False))\n",
    "    #print('Adding TimeDistributed Dense')\n",
    "    #model.add(TimeDistributed(Dense(EMBEDDING_SIZE)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = import_flickr8kdataset()\n",
    "# Currently testing it out\n",
    "dataset = [i for i in dataset[:100]]\n",
    "vocab,word_to_index, index_to_word = word_processing(dataset)\n",
    "#print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def process_images(dataset, coco=False, d_set=\"Flicker8k_Dataset\"):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    cnn_input = floatX(np.zeros((len(dataset), 3, 224, 224)))\n",
    "    rawim_input = []\n",
    "    sentences_tokens = []\n",
    "    for i, image in enumerate(dataset):\n",
    "        print \"ind_process %s total %s\" %(str(ind_process),str(total))\n",
    "        ind_process+=1\n",
    "        if coco:\n",
    "            fn = './coco/{}/{}'.format(image['filepath'], image['filename'])\n",
    "        else:\n",
    "            fn = d_set+'/{}'.format(image['filename'])\n",
    "        try:\n",
    "            im = plt.imread(fn)\n",
    "            rawim, cnn_input[i] = prep_image(im)\n",
    "            sentences_tokens.append(image['sentences'][0]['tokens'])\n",
    "            rawim_input.append(rawim)\n",
    "        except IOError:\n",
    "            continue\n",
    "    return rawim_input, cnn_input, sentences_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rawim_array, cnnim_array, sentences_tokens = process_images(dataset, coco=False, d_set=\"Flicker8k_Dataset\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_image_partial_captions(images, captions, word_to_index, vocab_count, model):\n",
    "    a_images = []\n",
    "    a_captions = []\n",
    "    next_words = []\n",
    "    #vocab_size = len(vocab)\n",
    "    for ind, image in enumerate(images):\n",
    "        sentence = captions[ind]\n",
    "        partial_caption_ar = np.zeros(SEQUENCE_LENGTH-1, dtype=np.int)\n",
    "        \n",
    "        words = ['<START>'] + sentence + ['<END>']\n",
    "        assert len(words)<SEQUENCE_LENGTH\n",
    "        for i in range(len(words) - 1):\n",
    "            pc_copy = partial_caption_ar.copy()\n",
    "            if words[i] in word_to_index:\n",
    "                pc_copy[i] = word_to_index[words[i]]\n",
    "            else:\n",
    "                pc_copy[i] = word_to_index[\"<UNK>\"]\n",
    "            a_images.append(image)\n",
    "            a_captions.append(pc_copy)\n",
    "            #Generate next word output vector\n",
    "            next_word = words[i + 1]\n",
    "            if next_word in word_to_index:\n",
    "                next_word_index = word_to_index[next_word]\n",
    "            else:\n",
    "                next_word_index = word_to_index[\"<UNK>\"]\n",
    "            next_word_ar = np.zeros(vocab_count, dtype=np.int)\n",
    "            next_word_ar[next_word_index] = 1\n",
    "            next_words.append(next_word_ar)\n",
    "    v_i = np.array(a_images)\n",
    "    v_c = np.array(a_captions)\n",
    "    v_nw = np.array(next_words)\n",
    "    return v_i, v_c, v_nw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vocab_count = len(word_to_index)\n",
    "#print cnnim_array.shape\n",
    "#v_i, v_c, v_nw = gen_image_partial_captions(cnnim_array, sentences_tokens, word_to_index, vocab_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_COUNT = len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def process_cnn_features(dataset, model, coco=False, d_set=\"Flicker8k_Dataset\"):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    for chunk in chunks(dataset, 25):\n",
    "        cnn_input = floatX(np.zeros((len(chunk), 3, 224, 224)))\n",
    "        for i, image in enumerate(chunk):\n",
    "            print \"ind_process %s total %s\" %(str(ind_process),str(total))\n",
    "            ind_process+=1\n",
    "            if coco:\n",
    "                fn = './coco/{}/{}'.format(image['filepath'], image['filename'])\n",
    "            else:\n",
    "                fn = d_set+'/{}'.format(image['filename'])\n",
    "            try:\n",
    "                im = plt.imread(fn)\n",
    "                _, cnn_input[i] = prep_image(im)\n",
    "            except IOError:\n",
    "                continue\n",
    "        features = model.predict(cnn_input)\n",
    "        print \"Processing Features For Chunk\"\n",
    "        for i, image in enumerate(chunk):\n",
    "            image['cnn features'] = features[i]\n",
    "            \n",
    "def process_captions_array(dataset):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    for chunk in chunks(dataset, 25):\n",
    "        for i in chunk:\n",
    "            \n",
    "            image[\"captions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VGG_16('weights/vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, images, index_to_word, word_to_index):\n",
    "    for image in images:\n",
    "        caption = np.zeros(SEQUENCE_LENGTH - 1).reshape(1, SEQUENCE_LENGTH - 1)\n",
    "        print(caption.shape)\n",
    "        caption[0,0] = word_to_index[\"<START>\"]\n",
    "        count=0\n",
    "        sentence = []\n",
    "        a = image.reshape(1,3,224,224)\n",
    "        #a = np.array([image])\n",
    "        while True:\n",
    "            out = model.predict([a, caption])\n",
    "            index = out.argmax(-1)\n",
    "            index = index[0]\n",
    "            word = index_to_word[index]\n",
    "            sentence.append(word)\n",
    "            count+= 1\n",
    "            if count >= SEQUENCE_LENGTH - 1 or index == word_to_index[\"<END>\"]: #max caption length reach of '<eos>' encountered\n",
    "                break\n",
    "            caption[0,count] = index\n",
    "        sent_str = \" \".join(sentence)\n",
    "        print(\"The Oracle says : %s\" %sent_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnim_list = []\n",
    "for i in cnnim_array:\n",
    "    cnnim_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict(model, cnnim_list, index_to_word, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caption = np.zeros(SEQUENCE_LENGTH).reshape(1, SEQUENCE_LENGTH)\n",
    "caption[0] = word_to_index[\"#START#\"]\n",
    "print cnnim_array[0].shape\n",
    "t = np.array(cnnim_array[0])\n",
    "print t.shape\n",
    "out = model.predict([v_i, v_c])\n",
    "print out\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
