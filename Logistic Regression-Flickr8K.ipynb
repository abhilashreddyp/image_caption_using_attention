{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn import linear_model\n",
    "\n",
    "from coreNlpUtil import *\n",
    "subject_word_to_indx = { \"ship\":2,\"boy\":4 }\n",
    "action_word_to_indx = {\"sail\" : 3 }\n",
    "object_word_to_indx = {\"sea\" : 5 }\n",
    "vocab_count = 6\n",
    "partial_captions = [(2,3,5)]\n",
    "cap = np.array([0,1,2,3,4]).reshape((5,1))\n",
    "images_features = np.arange(5000).reshape((5,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_samples = len(images_features)\n",
    "\n",
    "X_train = images_features\n",
    "y_train = cap\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "print('Logistic Regression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_train, y_train))\n",
    "logistic.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "d = pickle.load(open('flickr8k_Entire_dataset_with_cnn_features.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A black dog is running after a white dog in the snow .\n",
      "A little baby plays croquet .\n",
      "A brown dog in the snow has something hot pink in its mouth .\n",
      "A brown dog is running along a beach .\n",
      "A black and white dog with a red Frisbee standing on a sandy beach .\n",
      "A cyclist wearing a red helmet is riding on the pavement .\n",
      "A man dressed in a purple shirt and red bandanna smiles at the people watching him .\n",
      "A boy wearing a red t-shirt is running through woodland .\n",
      "A girl in a white dress .\n",
      "A skier in a yellow jacket is airborne above the mountains .\n"
     ]
    }
   ],
   "source": [
    "for i in (d[:10]):\n",
    "    print i['sentences'][0]['raw']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"dog\"\n",
    "\"run\"\n",
    "\"snow\"\n",
    "\n",
    "\"baby\" \n",
    "\"play\"\n",
    "\"truck\"\n",
    "\n",
    "\"dog\"\n",
    "\"hold\"\n",
    "\"snow\"\n",
    "\n",
    "\n",
    "\"dog\" \n",
    "\"run\"\n",
    "\"beach\"\n",
    "\n",
    "\n",
    "\"dog\"\n",
    "\"stand\"\n",
    "\"beach\"\n",
    "\n",
    "\"cyclist\"\n",
    "\"ride\"\n",
    "\"pavement\"\n",
    "\n",
    "\n",
    "A man dressed in a purple shirt and red bandanna smiles at the people watching him .\n",
    "A boy wearing a red t-shirt is running through woodland .\n",
    "A girl in a white dress .\n",
    "A skier in a yellow jacket is airborne above the mountains ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subj_word_dict = {\"dog\":1,\"baby\":2,\"cyclist\":3}\n",
    "action_word_dict = {\"run\":1,\"play\":2, \"hold\":3, \"stand\":4, \"ride\":5}\n",
    "area_word_dict = {\"snow\":1, \"truck\":2, \"beach\": 3, \"pavement\":4}\n",
    "y_sub = np.array([1,2,1,1,1,3])\n",
    "y_action = np.array([1,2,3,1,4,5])\n",
    "y_area = np.array([1,2,1,3,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in (d[:6]):\n",
    "    X_train.append(i['cnn features'])\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 0.666667\n",
      "Logistic Regression score: 0.666667\n",
      "Logistic Regression score: 0.666667\n"
     ]
    }
   ],
   "source": [
    "logistic_subject = linear_model.LogisticRegression()\n",
    "logistic_action = linear_model.LogisticRegression()\n",
    "logistic_area = linear_model.LogisticRegression()\n",
    "\n",
    "print('Logistic Regression score: %f'\n",
    "      % logistic_subject.fit(X_train, y_sub).score(X_train, y_sub))\n",
    "\n",
    "print('Logistic Regression score: %f'\n",
    "      % logistic_action.fit(X_train, y_action).score(X_train, y_action))\n",
    "\n",
    "print('Logistic Regression score: %f'\n",
    "      % logistic_area.fit(X_train, y_area).score(X_train, y_area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 1, 4, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_action.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def remove_char_dep_res(text):\n",
    "    return re.sub(\"{.*}\",\"\",text)\n",
    "\n",
    "def process_text(triplet):\n",
    "    return re.sub(\"{.*}\",\"\",triplet[0]), re.sub(\"{.*}\",\"\",triplet[1]), re.sub(\"{.*}\",\"\",triplet[2])\n",
    "    #triplet[1] = \n",
    "    #triplet[2] = re.sub(\"{.*}\",\"\",triplet[2])\n",
    "    #return triplet\n",
    "\n",
    "def find_category_pos(pos):\n",
    "    if(pos in [\"VBG\"]):\n",
    "        return \"Verb\"\n",
    "    if(pos in [\"NN\"]):\n",
    "        return \"Noun\"\n",
    "    return \"UNKNOWN Category\"\n",
    "\n",
    "def find_triplet_nltk(root, prep_parses, dep_parse):\n",
    "    Verb = []\n",
    "    Noun = []\n",
    "    if len(root) == 0:\n",
    "        return None\n",
    "    for prep_parse in prep_parses:\n",
    "        if(root == prep_parse[1]):\n",
    "            word = (remove_char_dep_res(prep_parse[0]))\n",
    "            #print word\n",
    "            #print find_category_pos(nltk.pos_tag([word])[0][1])\n",
    "            if(find_category_pos(nltk.pos_tag([word])[0][1]) == \"Verb\"):\n",
    "                \n",
    "                Verb.append(word)\n",
    "            if(find_category_pos(nltk.pos_tag([word])[0][1]) == \"Noun\"):\n",
    "                Noun.append(word)\n",
    "            if(len(Verb) >= 1 and len(Noun) >= 1):\n",
    "                break;\n",
    "    if(len(Verb) >= 1 and len(Noun) >= 1):\n",
    "        return (remove_char_dep_res(root), Verb[0], Noun[0])\n",
    "    for parse in dep_parse:\n",
    "        m = re.search(\"prep_(.*)\", parse[0])\n",
    "        if(m):\n",
    "            return process_text((root, m.group(1), parse[2]))\n",
    "        \n",
    "    return None   \n",
    "\n",
    "def triplet(dep_parse):\n",
    "    nsubj = []\n",
    "    dobj = []\n",
    "    prep = []\n",
    "    root = \"\"\n",
    "    for parse in dep_parse:\n",
    "        if  parse[0] == \"nsubj\":\n",
    "            nsubj.append( (parse[2], parse[1]) )\n",
    "\n",
    "        elif  parse[0] == \"dobj\":\n",
    "            dobj.append( (parse[2], parse[1]) )\n",
    "\n",
    "        elif re.search(\"prep_\", parse[0]):\n",
    "            prep.append((parse[2], parse[1]))\n",
    "\n",
    "        elif parse[0] == \"root\":\n",
    "            root = parse[2]\n",
    "    found = False\n",
    "    if(len(nsubj)>0):\n",
    "        for nsubj_dep in nsubj:\n",
    "            for dobj_dep in dobj:\n",
    "                if(nsubj_dep[1] == dobj_dep[1]):\n",
    "                    triplet = process_text((nsubj_dep[0], nsubj_dep[1], dobj_dep[0]))\n",
    "                    print triplet\n",
    "                    found = True\n",
    "                    break;\n",
    "            if(found):\n",
    "                break;\n",
    "            \n",
    "            for prep_dep in prep:\n",
    "                if(nsubj_dep[1] == prep_dep[1]):\n",
    "                    triplet = process_text((nsubj_dep[0], nsubj_dep[1], prep_dep[0]))\n",
    "                    print triplet\n",
    "                    found = True\n",
    "                    break;\n",
    "            if(found):\n",
    "                break;\n",
    "    else:\n",
    "        if(len(root)>0):\n",
    "            trip = find_triplet_nltk(root, prep, dep_parse)\n",
    "            if(trip!= None):\n",
    "                triplet = trip\n",
    "                print triplet\n",
    "                found = True\n",
    "    if(found == False):\n",
    "        print \"SUBJECTS are \"\n",
    "        print nsubj\n",
    "        print \"OBJECTS are \"\n",
    "        print dobj\n",
    "        print \"PREP are \"\n",
    "        print prep\n",
    "        print \"Entire Dep Parse\"\n",
    "        print dep_parse\n",
    "        return None\n",
    "    else:\n",
    "        return triplet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ma-sultan/monolingual-word-aligner\n",
    "https://github.com/dasmith/stanford-corenlp-python\n",
    "Follow above instructions in the monolingual word aligner including the one which states to modify the certain line number 100, THen RUN the Corenlp server and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_dataset(dataset):\n",
    "    Triplets = []\n",
    "    X_train = []\n",
    "    for i in (dataset):\n",
    "        print i['sentences'][0]['raw']\n",
    "        sentence1ParseResult = parseText(i['sentences'][0]['raw'])\n",
    "        result = dependencyParseAndPutOffsets(sentence1ParseResult)\n",
    "        triplet_value = triplet(result)\n",
    "        Triplets.append(triplet_value)\n",
    "        X_train.append(i['cnn features'])\n",
    "        #print result\n",
    "        print \"\"\n",
    "    return np.array(X_train), Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_triplet_dictionary(allTriplets):\n",
    "    subj_vocab = []\n",
    "    action_vocab = []\n",
    "    object_vocab = []\n",
    "    for triplet in allTriplets:\n",
    "        subj_vocab.append(triplet[0])\n",
    "        action_vocab.append(triplet[1])\n",
    "        object_vocab.append(triplet[2])\n",
    "    subj_vocab.append(\"UNK\")\n",
    "    action_vocab.append(\"UNK\")\n",
    "    object_vocab.append(\"UNK\")\n",
    "    subj_word_to_index = {w: i for i, w in enumerate(subj_vocab)}\n",
    "    subj_index_to_word = {i: w for i, w in enumerate(subj_vocab)}\n",
    "    action_word_to_index = {w: i for i, w in enumerate(action_vocab)}\n",
    "    action_index_to_word = {i: w for i, w in enumerate(action_vocab)}\n",
    "    object_word_to_index = {w: i for i, w in enumerate(object_vocab)}\n",
    "    object_index_to_word = {i: w for i, w in enumerate(object_vocab)}\n",
    "    #print subj_word_to_index,subj_index_to_word,action_word_to_index,action_index_to_word,object_word_to_index,object_index_to_word\n",
    "    return subj_word_to_index,subj_index_to_word,action_word_to_index,action_index_to_word,object_word_to_index,object_index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_y_values(allTriplets,subj_word_to_index,action_word_to_index,object_word_to_index):\n",
    "    y_subj = []\n",
    "    y_action = []\n",
    "    y_obj = []\n",
    "    for triplet in allTriplets:\n",
    "        if(triplet[0] in subj_word_to_index):\n",
    "            y_subj.append(subj_word_to_index[triplet[0]])\n",
    "        else:\n",
    "            y_subj.append(subj_word_to_index[\"UNK\"])\n",
    "        if(triplet[1] in action_word_to_index):\n",
    "            y_action.append(action_word_to_index[triplet[1]])\n",
    "        else:\n",
    "            y_action.append(action_word_to_index[\"UNK\"])\n",
    "        if(triplet[2] in object_word_to_index):\n",
    "            y_obj.append(object_word_to_index[triplet[2]])\n",
    "        else:\n",
    "            y_obj.append(object_word_to_index[\"UNK\"])\n",
    "    return np.array(y_subj), np.array(y_action), np.array(y_obj)\n",
    "\n",
    "def print_output(y_sub, y_action, y_obj, subj_index_to_word, action_index_to_word, object_index_to_word):\n",
    "    for i in range(len(y_sub)):\n",
    "        print subj_index_to_word[y_sub[i]], action_index_to_word[y_action[i]], object_index_to_word[y_obj[i]]\n",
    "\n",
    "def train_model(X_train, y_sub, y_action, y_area):\n",
    "    logistic_subject = linear_model.LogisticRegression()\n",
    "    logistic_action = linear_model.LogisticRegression()\n",
    "    logistic_area = linear_model.LogisticRegression()\n",
    "\n",
    "    print('Logistic Regression score: %f'\n",
    "          % logistic_subject.fit(X_train, y_sub).score(X_train, y_sub))\n",
    "\n",
    "    print('Logistic Regression score: %f'\n",
    "          % logistic_action.fit(X_train, y_action).score(X_train, y_action))\n",
    "\n",
    "    print('Logistic Regression score: %f'\n",
    "          % logistic_area.fit(X_train, y_area).score(X_train, y_area))\n",
    "    return logistic_subject, logistic_action, logistic_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A black dog is running after a white dog in the snow .\n",
      "(u'dog', u'running', u'dog')\n",
      "\n",
      "A little baby plays croquet .\n",
      "(u'baby', u'plays', u'croquet')\n",
      "\n",
      "A brown dog in the snow has something hot pink in its mouth .\n",
      "(u'dog', u'has', u'pink')\n",
      "\n",
      "A brown dog is running along a beach .\n",
      "(u'dog', u'running', u'beach')\n",
      "\n",
      "A black and white dog with a red Frisbee standing on a sandy beach .\n",
      "(u'dog', u'standing', u'beach')\n",
      "\n",
      "A cyclist wearing a red helmet is riding on the pavement .\n",
      "(u'cyclist', u'riding', u'pavement')\n",
      "\n",
      "A man dressed in a purple shirt and red bandanna smiles at the people watching him .\n",
      "(u'people', u'watching', u'him')\n",
      "\n",
      "A boy wearing a red t-shirt is running through woodland .\n",
      "(u'boy', u'running', u'woodland')\n",
      "\n",
      "A girl in a white dress .\n",
      "(u'girl', u'in', u'dress')\n",
      "\n",
      "A skier in a yellow jacket is airborne above the mountains .\n",
      "(u'skier', u'airborne', u'mountains')\n",
      "\n",
      "A photographer looks over the hills .\n",
      "(u'photographer', u'looks', u'hills')\n",
      "\n",
      "A bunch of girls in cheerleader outfits .\n",
      "(u'bunch', u'of', u'girls')\n",
      "\n",
      "A blue boat with a yellow canopy is floating on calm waters .\n",
      "(u'boat', u'floating', u'waters')\n",
      "\n",
      "A dog catches a Frisbee in midair .\n",
      "(u'dog', u'catches', u'Frisbee')\n",
      "\n",
      "A little old lady sitting next to an advertisement .\n",
      "(u'lady', u'next_to', u'advertisement')\n",
      "\n",
      "A blond girl wearing a green jacket walks on a trail along side a metal fence .\n",
      "(u'girl', u'walks', u'trail')\n",
      "\n",
      "A family of nine people , including four children , pose in front of a brick fireplace with a white mantle .\n",
      "(u'family', u'pose', u'fireplace')\n",
      "\n",
      "Man in a sweater pointing at the camera .\n",
      "(u'Man', u'in', u'sweater')\n",
      "\n",
      "A dog looks warily at the brown dog investigating his area .\n",
      "(u'dog', u'looks', u'dog')\n",
      "\n",
      "three children in a field with white flowers\n",
      "(u'children', u'in', u'field')\n",
      "\n",
      "dog running dog\n",
      "baby plays croquet\n",
      "dog has pink\n",
      "dog running beach\n",
      "dog standing beach\n",
      "cyclist riding pavement\n",
      "people watching him\n",
      "boy running woodland\n",
      "girl in dress\n",
      "skier airborne mountains\n",
      "photographer looks hills\n",
      "bunch of girls\n",
      "boat floating waters\n",
      "dog catches Frisbee\n",
      "lady next_to advertisement\n",
      "girl walks trail\n",
      "family pose fireplace\n",
      "Man in sweater\n",
      "dog looks dog\n",
      "children in field\n"
     ]
    }
   ],
   "source": [
    "X_train, Triplets = process_dataset(d[:20])\n",
    "subj_word_to_index,subj_index_to_word,action_word_to_index,action_index_to_word,object_word_to_index,object_index_to_word = process_triplet_dictionary(Triplets)\n",
    "y_sub_train,y_action_train,y_obj_train = get_y_values(Triplets,subj_word_to_index,action_word_to_index,object_word_to_index)\n",
    "print_output(y_sub_train, y_action_train, y_obj_train, subj_index_to_word, action_index_to_word, object_index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 0.300000\n",
      "Logistic Regression score: 0.300000\n",
      "Logistic Regression score: 0.400000\n"
     ]
    }
   ],
   "source": [
    "lr_s,lr_a,lr_o = train_model(X_train, y_sub_train, y_action_train, y_obj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_s = lr_s.predict(X_train)\n",
    "y_pred_a = lr_a.predict(X_train)\n",
    "y_pred_o = lr_o.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog running dog\n",
      "dog in dog\n",
      "dog in pink\n",
      "dog running beach\n",
      "dog in beach\n",
      "dog in dog\n",
      "dog in dog\n",
      "dog in dog\n",
      "dog in dog\n",
      "dog in mountains\n",
      "dog looks hills\n",
      "dog in girls\n",
      "dog in dog\n",
      "dog running dog\n",
      "dog in dog\n",
      "dog in trail\n",
      "dog in dog\n",
      "dog in dog\n",
      "dog running beach\n",
      "dog in dog\n"
     ]
    }
   ],
   "source": [
    "print_output(y_pred_s, y_pred_a, y_pred_o, subj_index_to_word, action_index_to_word, object_index_to_word)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
