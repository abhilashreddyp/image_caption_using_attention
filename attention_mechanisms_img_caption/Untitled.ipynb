{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as tensor\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dataset(name):\n",
    "    return datasets[name][0], datasets[name][1]\n",
    "\n",
    "# make prefix-appended name\n",
    "def _p(pp, name):\n",
    "    return '%s_%s' % (pp, name)\n",
    "\n",
    "# initialize Theano shared variables according to the initial parameters\n",
    "def init_tparams(params):\n",
    "    tparams = OrderedDict()\n",
    "    for kk, pp in params.iteritems():\n",
    "        tparams[kk] = theano.shared(params[kk], name=kk)\n",
    "    return tparams\n",
    "\n",
    "# load parameters\n",
    "def load_params(path, params):\n",
    "    pp = numpy.load(path)\n",
    "    for kk, vv in params.iteritems():\n",
    "        if kk not in pp:\n",
    "            raise Warning('%s is not in the archive' % kk)\n",
    "        params[kk] = pp[kk]\n",
    "\n",
    "    return params\n",
    "\n",
    "# some utilities\n",
    "def ortho_weight(ndim):\n",
    "    \"\"\"\n",
    "    Random orthogonal weights\n",
    "\n",
    "    Used by norm_weights(below), in which case, we\n",
    "    are ensuring that the rows are orthogonal\n",
    "    (i.e W = U \\Sigma V, U has the same\n",
    "    # of rows, V has the same # of cols)\n",
    "    \"\"\"\n",
    "    W = numpy.random.randn(ndim, ndim)\n",
    "    u, _, _ = numpy.linalg.svd(W)\n",
    "    return u.astype('float32')\n",
    "\n",
    "def norm_weight(nin,nout=None, scale=0.01, ortho=True):\n",
    "    \"\"\"\n",
    "    Random weights drawn from a Gaussian\n",
    "    \"\"\"\n",
    "    if nout is None:\n",
    "        nout = nin\n",
    "    if nout == nin and ortho:\n",
    "        W = ortho_weight(nin)\n",
    "    else:\n",
    "        W = scale * numpy.random.randn(nin, nout)\n",
    "    return W.astype('float32')\n",
    "\n",
    "# some useful shorthands\n",
    "def tanh(x):\n",
    "    return tensor.tanh(x)\n",
    "\n",
    "def rectifier(x):\n",
    "    return tensor.maximum(0., x)\n",
    "\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Neural network layer definitions.\n",
    "\n",
    "The life-cycle of each of these layers is as follows\n",
    "    1) The param_init of the layer is called, which creates\n",
    "    the weights of the network.\n",
    "    2) The fprop is called which builds that part of the Theano graph\n",
    "    using the weights created in step 1). This automatically links\n",
    "    these variables to the graph.\n",
    "\n",
    "Each prefix is used like a key and should be unique\n",
    "to avoid naming conflicts when building the graph.\n",
    "\"\"\"\n",
    "# layers: 'name': ('parameter initializer', 'fprop')\n",
    "layers = {'ff': ('param_init_fflayer', 'fflayer'),\n",
    "          'lstm': ('param_init_lstm', 'lstm_layer'),\n",
    "          'lstm_cond': ('param_init_lstm_cond', 'lstm_cond_layer'),\n",
    "          }\n",
    "\n",
    "def get_layer(name):\n",
    "    fns = layers[name]\n",
    "    return (eval(fns[0]), eval(fns[1]))\n",
    "\n",
    "\n",
    "# feedforward layer: affine transformation + point-wise nonlinearity\n",
    "def param_init_fflayer(options, params, prefix='ff', nin=None, nout=None):\n",
    "    if nin is None:\n",
    "        nin = options['dim_proj']\n",
    "    if nout is None:\n",
    "        nout = options['dim_proj']\n",
    "    params[_p(prefix, 'W')] = norm_weight(nin, nout, scale=0.01)\n",
    "    params[_p(prefix, 'b')] = numpy.zeros((nout,)).astype('float32')\n",
    "\n",
    "    return params\n",
    "\n",
    "def fflayer(tparams, state_below, options, prefix='rconv', activ='lambda x: tensor.tanh(x)', **kwargs):\n",
    "    return eval(activ)(tensor.dot(state_below, tparams[_p(prefix,'W')])+tparams[_p(prefix,'b')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
