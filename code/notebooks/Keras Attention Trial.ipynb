{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 960M (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5105)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "import time\n",
    "import theano\n",
    "import keras\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict\n",
    "import six.moves.cPickle as pkl\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, LSTM, Lambda, merge\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D \n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import GRU, TimeDistributed, RepeatVector, Merge, TimeDistributedDense\n",
    "import h5py\n",
    "import json\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from attention_lstm import AttentionLSTM\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback\n",
    "#import theano.tensor as T\n",
    "#import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "SEQUENCE_LENGTH = 45\n",
    "MAX_SENTENCE_LENGTH = SEQUENCE_LENGTH - 3 # 1 for image, 1 for start token, 1 for end token\n",
    "BATCH_SIZE = 20\n",
    "OUTPUT_DIM = 512\n",
    "ANNOTATION_DIM = 512\n",
    "WORD_DIM = 512\n",
    "ANNOTATION_SIZE=196\n",
    "ANNOTION_LENGTH = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "with open('features/flickr30kann_1000_p3.pkl', 'rb') as f:\n",
    "    d = pkl.load(f)\n",
    "#pkl.dump(d, open('features/flickr30kann_1000_p3.pkl', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "vocab = d['vocab']\n",
    "word_to_index = d['word_to_index']\n",
    "index_to_word = d['index_to_word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 44, 2452)\n",
      "(1000, 44, 2452)\n",
      "(1000, 196, 512)\n",
      "(1000, 512)\n"
     ]
    }
   ],
   "source": [
    "ins = d['INS']\n",
    "gts = d['GTS']\n",
    "ann_vec = d['AnnotationVectors']\n",
    "ann_vec = ann_vec.reshape(1000,196,512)\n",
    "z_mean = np.mean(ann_vec, axis=1)\n",
    "print(ins.shape)\n",
    "print(gts.shape)\n",
    "print(ann_vec.shape)\n",
    "print(z_mean.shape)\n",
    "VOCAB_COUNT = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 44, 2452)\n",
      "(100, 44, 2452)\n",
      "(900, 512)\n",
      "(100, 44, 2452)\n",
      "(900, 196, 512)\n"
     ]
    }
   ],
   "source": [
    "ins_train = ins[0:900, :, :]\n",
    "gts_train = gts[0:900, :, :]\n",
    "ann_vec_train = ann_vec[0:900, :, :]\n",
    "z_mean_train = z_mean[0:900, :]\n",
    "\n",
    "ins_test = ins[900:, :, :]\n",
    "gts_test = gts[900:, :, :]\n",
    "ann_vec_test = ann_vec[900:, :, :]\n",
    "z_mean_test = z_mean[900:, :]\n",
    "\n",
    "x_train = [ins_train, ann_vec_train, z_mean_train]\n",
    "x_test = [ins_test, ann_vec_test, z_mean_test]\n",
    "\n",
    "y_train = gts_train\n",
    "y_test = gts_test\n",
    "print(ins_train.shape)\n",
    "print(ins_test.shape)\n",
    "print(z_mean_train.shape)\n",
    "print(gts_test.shape)\n",
    "print(ann_vec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model\n",
      "Softmax.0\n",
      "Softmax.0\n",
      "input shapes [(None, 44, 512), (None, 512), (None, 512), (None, 196, 512)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\nprint('Adding Embedding')\\nmodel.add(Embedding(VOCAB_COUNT, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH-1))\\nprint('Adding LSTM')\\nmodel.add(AttentionLSTM(EMBEDDING_SIZE, Z_DIM, return_sequences=True))\\nprint('Adding TimeDistributed Dense')\\nmodel.add(TimeDistributed(Dense(EMBEDDING_SIZE)))\\nreturn model\\nmodel.add(Dense(VOCAB_COUNT, activation='softmax'))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aLstm_Layer = None\n",
    "\n",
    "print('Building Model')\n",
    "x_inp = Input(shape=(SEQUENCE_LENGTH-1, VOCAB_COUNT))\n",
    "z_inp = Input(shape=(ANNOTATION_SIZE, ANNOTATION_DIM,))\n",
    "z_mean = Input(shape=(ANNOTATION_DIM,))\n",
    "h_Dense_l = Dense(OUTPUT_DIM, input_dim=ANNOTATION_DIM, activation='softmax')\n",
    "h_Dense = h_Dense_l(z_mean)\n",
    "c_Dense = Dense(OUTPUT_DIM, input_dim=ANNOTATION_DIM, activation='softmax')(z_mean)\n",
    "#emb = Embedding(VOCAB_COUNT, WORD_DIM, input_length=SEQUENCE_LENGTH-1)(x_inp)\n",
    "#tdemb = TimeDistributed()(emb)\n",
    "xt_dense = TimeDistributed(Dense(WORD_DIM))(x_inp)\n",
    "print(h_Dense)\n",
    "print(c_Dense)\n",
    "#print(tdemb)\n",
    "#merge1 = merge([emb, h_Dense, c_Dense, z_inp], mode='concat', concat_axis=-1)\n",
    "#global aLstm_Layer\n",
    "aLstm_Layer = AttentionLSTM( output_dim=WORD_DIM, z_dim=ANNOTATION_DIM, W_regularizer=l2(0.01), U_regularizer=l2(0.01), Z_regularizer=l2(0.01), dropout_W=0.3, dropout_U=0.3, dropout_Z=0.3, return_sequences=True)\n",
    "aLstm = aLstm_Layer([xt_dense, h_Dense, c_Dense, z_inp])\n",
    "#aLstm_Alpha_Layer = AttentionLSTM(ret_alpha=True, output_dim=ANNOTION_LENGTH, z_dim=ANNOTATION_DIM, W_regularizer=l2(0.01), U_regularizer=l2(0.01), Z_regularizer=l2(0.01), dropout_W=0.3, dropout_U=0.3, dropout_Z=0.3, return_sequences=True)\n",
    "#aLstm_Alpha = aLstm_Alpha_Layer([xt_dense, h_Dense, c_Dense, z_inp])\n",
    "tdense = TimeDistributed(Dense(VOCAB_COUNT))(aLstm)\n",
    "act = Activation('softmax')(tdense)\n",
    "model = Model(input=[x_inp, z_inp, z_mean], output=act)\n",
    "'''\n",
    "model = Sequential()\n",
    "print('Adding Embedding')\n",
    "model.add(Embedding(VOCAB_COUNT, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH-1))\n",
    "print('Adding LSTM')\n",
    "model.add(AttentionLSTM(EMBEDDING_SIZE, Z_DIM, return_sequences=True))\n",
    "print('Adding TimeDistributed Dense')\n",
    "model.add(TimeDistributed(Dense(EMBEDDING_SIZE)))\n",
    "return model\n",
    "model.add(Dense(VOCAB_COUNT, activation='softmax'))\n",
    "'''\n",
    "#print(model.summary())\n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AlphaCallback(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.alphaz = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.alphaz.append(K.get_value(aLstm_Layer.states[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 44, 2452)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           262656      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 512)           262656      input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 196, 512)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribute(None, 44, 512)       1255936     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attentionlstm_1 (AttentionLSTM)  (None, 44, 512)       3677185     timedistributed_1[0][0]          \n",
      "                                                                   dense_1[0][0]                    \n",
      "                                                                   dense_2[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_2 (TimeDistribute(None, 44, 2452)      1257876     attentionlstm_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 44, 2452)      0           timedistributed_2[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 6716309\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model = build_model()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "900/900 [==============================] - 55s - loss: 6.1549 - acc: 0.6109    \n",
      "Epoch 2/200\n",
      "900/900 [==============================] - 55s - loss: 2.1918 - acc: 0.6626    \n",
      "Epoch 3/200\n",
      "900/900 [==============================] - 53s - loss: 2.0607 - acc: 0.6728    \n",
      "Epoch 4/200\n",
      "900/900 [==============================] - 52s - loss: 1.9872 - acc: 0.6783    \n",
      "Epoch 5/200\n",
      "900/900 [==============================] - 53s - loss: 1.9243 - acc: 0.6838    \n",
      "Epoch 6/200\n",
      "900/900 [==============================] - 53s - loss: 1.8787 - acc: 0.6871    \n",
      "Epoch 7/200\n",
      "900/900 [==============================] - 54s - loss: 1.8410 - acc: 0.6906    \n",
      "Epoch 8/200\n",
      "900/900 [==============================] - 54s - loss: 1.8053 - acc: 0.6947    \n",
      "Epoch 9/200\n",
      "900/900 [==============================] - 55s - loss: 1.7820 - acc: 0.6962    \n",
      "Epoch 10/200\n",
      "900/900 [==============================] - 54s - loss: 1.7478 - acc: 0.6997    \n",
      "Epoch 11/200\n",
      "900/900 [==============================] - 54s - loss: 1.7081 - acc: 0.7043    \n",
      "Epoch 12/200\n",
      "900/900 [==============================] - 54s - loss: 1.6865 - acc: 0.7084    \n",
      "Epoch 13/200\n",
      "900/900 [==============================] - 54s - loss: 1.6529 - acc: 0.7109    \n",
      "Epoch 14/200\n",
      "900/900 [==============================] - 55s - loss: 1.6270 - acc: 0.7149    \n",
      "Epoch 15/200\n",
      "900/900 [==============================] - 54s - loss: 1.5861 - acc: 0.7202    \n",
      "Epoch 16/200\n",
      "900/900 [==============================] - 58s - loss: 1.5551 - acc: 0.7254    \n",
      "Epoch 17/200\n",
      "900/900 [==============================] - 57s - loss: 1.5099 - acc: 0.7314    \n",
      "Epoch 18/200\n",
      "900/900 [==============================] - 55s - loss: 1.4889 - acc: 0.7371    \n",
      "Epoch 19/200\n",
      "900/900 [==============================] - 54s - loss: 1.4593 - acc: 0.7418    \n",
      "Epoch 20/200\n",
      "900/900 [==============================] - 54s - loss: 1.4217 - acc: 0.7491    \n",
      "Epoch 21/200\n",
      "900/900 [==============================] - 54s - loss: 1.3899 - acc: 0.7549    \n",
      "Epoch 22/200\n",
      "900/900 [==============================] - 55s - loss: 1.3594 - acc: 0.7629    \n",
      "Epoch 23/200\n",
      "900/900 [==============================] - 54s - loss: 1.3137 - acc: 0.7699    \n",
      "Epoch 24/200\n",
      "900/900 [==============================] - 58s - loss: 1.2639 - acc: 0.7779    \n",
      "Epoch 25/200\n",
      "900/900 [==============================] - 56s - loss: 1.2325 - acc: 0.7858    \n",
      "Epoch 26/200\n",
      "900/900 [==============================] - 55s - loss: 1.2025 - acc: 0.7942    \n",
      "Epoch 27/200\n",
      "900/900 [==============================] - 55s - loss: 1.1630 - acc: 0.8015    \n",
      "Epoch 28/200\n",
      "900/900 [==============================] - 55s - loss: 1.1311 - acc: 0.8080    \n",
      "Epoch 29/200\n",
      "900/900 [==============================] - 56s - loss: 1.0882 - acc: 0.8166    \n",
      "Epoch 30/200\n",
      "900/900 [==============================] - 56s - loss: 1.0651 - acc: 0.8218    \n",
      "Epoch 31/200\n",
      "900/900 [==============================] - 56s - loss: 1.0194 - acc: 0.8298    \n",
      "Epoch 32/200\n",
      "900/900 [==============================] - 56s - loss: 0.9763 - acc: 0.8363    \n",
      "Epoch 33/200\n",
      "900/900 [==============================] - 56s - loss: 0.9463 - acc: 0.8431    \n",
      "Epoch 34/200\n",
      "900/900 [==============================] - 55s - loss: 0.9170 - acc: 0.8497    \n",
      "Epoch 35/200\n",
      "900/900 [==============================] - 54s - loss: 0.8939 - acc: 0.8555    \n",
      "Epoch 36/200\n",
      "900/900 [==============================] - 55s - loss: 0.8638 - acc: 0.8592    \n",
      "Epoch 37/200\n",
      "900/900 [==============================] - 54s - loss: 0.8462 - acc: 0.8645    \n",
      "Epoch 38/200\n",
      "900/900 [==============================] - 55s - loss: 0.8263 - acc: 0.8704    \n",
      "Epoch 39/200\n",
      "900/900 [==============================] - 54s - loss: 0.8030 - acc: 0.8725    \n",
      "Epoch 40/200\n",
      "900/900 [==============================] - 54s - loss: 0.7831 - acc: 0.8750    \n",
      "Epoch 41/200\n",
      "900/900 [==============================] - 54s - loss: 0.7758 - acc: 0.8765    \n",
      "Epoch 42/200\n",
      "900/900 [==============================] - 54s - loss: 0.7268 - acc: 0.8868    \n",
      "Epoch 43/200\n",
      "900/900 [==============================] - 57s - loss: 0.7060 - acc: 0.8909    \n",
      "Epoch 44/200\n",
      "900/900 [==============================] - 54s - loss: 0.6899 - acc: 0.8926    \n",
      "Epoch 45/200\n",
      "900/900 [==============================] - 55s - loss: 0.6794 - acc: 0.8948    \n",
      "Epoch 46/200\n",
      "900/900 [==============================] - 54s - loss: 0.6352 - acc: 0.9038    \n",
      "Epoch 47/200\n",
      "900/900 [==============================] - 55s - loss: 0.6098 - acc: 0.9069    \n",
      "Epoch 48/200\n",
      "900/900 [==============================] - 54s - loss: 0.6041 - acc: 0.9075    \n",
      "Epoch 49/200\n",
      "900/900 [==============================] - 54s - loss: 0.5698 - acc: 0.9145    \n",
      "Epoch 50/200\n",
      "900/900 [==============================] - 54s - loss: 0.5587 - acc: 0.9180    \n",
      "Epoch 51/200\n",
      "900/900 [==============================] - 54s - loss: 0.5498 - acc: 0.9181    \n",
      "Epoch 52/200\n",
      "900/900 [==============================] - 58s - loss: 0.5460 - acc: 0.9192    \n",
      "Epoch 53/200\n",
      "900/900 [==============================] - 55s - loss: 0.5398 - acc: 0.9211    \n",
      "Epoch 54/200\n",
      "900/900 [==============================] - 55s - loss: 0.5203 - acc: 0.9235    \n",
      "Epoch 55/200\n",
      "900/900 [==============================] - 55s - loss: 0.4910 - acc: 0.9286    \n",
      "Epoch 56/200\n",
      "900/900 [==============================] - 55s - loss: 0.4600 - acc: 0.9335    \n",
      "Epoch 57/200\n",
      "900/900 [==============================] - 56s - loss: 0.4505 - acc: 0.9351    \n",
      "Epoch 58/200\n",
      "900/900 [==============================] - 54s - loss: 0.4468 - acc: 0.9360    \n",
      "Epoch 59/200\n",
      "900/900 [==============================] - 57s - loss: 0.4404 - acc: 0.9366    \n",
      "Epoch 60/200\n",
      "900/900 [==============================] - 54s - loss: 0.4426 - acc: 0.9355    \n",
      "Epoch 61/200\n",
      "900/900 [==============================] - 54s - loss: 0.4357 - acc: 0.9373    \n",
      "Epoch 62/200\n",
      "900/900 [==============================] - 54s - loss: 0.4309 - acc: 0.9384    \n",
      "Epoch 63/200\n",
      "900/900 [==============================] - 55s - loss: 0.4354 - acc: 0.9374    \n",
      "Epoch 64/200\n",
      "900/900 [==============================] - 55s - loss: 0.4244 - acc: 0.9408    \n",
      "Epoch 65/200\n",
      "900/900 [==============================] - 55s - loss: 0.4151 - acc: 0.9415    \n",
      "Epoch 66/200\n",
      "900/900 [==============================] - 56s - loss: 0.3866 - acc: 0.9456    \n",
      "Epoch 67/200\n",
      "900/900 [==============================] - 56s - loss: 0.3782 - acc: 0.9472    \n",
      "Epoch 68/200\n",
      "900/900 [==============================] - 58s - loss: 0.3794 - acc: 0.9478    \n",
      "Epoch 69/200\n",
      "900/900 [==============================] - 56s - loss: 0.3643 - acc: 0.9498    \n",
      "Epoch 70/200\n",
      "900/900 [==============================] - 56s - loss: 0.3585 - acc: 0.9505    \n",
      "Epoch 71/200\n",
      "900/900 [==============================] - 54s - loss: 0.3550 - acc: 0.9494    \n",
      "Epoch 72/200\n",
      "900/900 [==============================] - 54s - loss: 0.3526 - acc: 0.9518    \n",
      "Epoch 73/200\n",
      "900/900 [==============================] - 54s - loss: 0.3412 - acc: 0.9526    \n",
      "Epoch 74/200\n",
      "900/900 [==============================] - 54s - loss: 0.3361 - acc: 0.9529    \n",
      "Epoch 75/200\n",
      "900/900 [==============================] - 55s - loss: 0.3447 - acc: 0.9529    \n",
      "Epoch 76/200\n",
      "900/900 [==============================] - 55s - loss: 0.3426 - acc: 0.9522    \n",
      "Epoch 77/200\n",
      "900/900 [==============================] - 55s - loss: 0.3539 - acc: 0.9507    \n",
      "Epoch 78/200\n",
      "900/900 [==============================] - 54s - loss: 0.3469 - acc: 0.9517    \n",
      "Epoch 79/200\n",
      "900/900 [==============================] - 56s - loss: 0.3532 - acc: 0.9509    \n",
      "Epoch 80/200\n",
      "900/900 [==============================] - 56s - loss: 0.3372 - acc: 0.9540    \n",
      "Epoch 81/200\n",
      "900/900 [==============================] - 55s - loss: 0.3283 - acc: 0.9550    \n",
      "Epoch 82/200\n",
      "900/900 [==============================] - 56s - loss: 0.3321 - acc: 0.9543    \n",
      "Epoch 83/200\n",
      "900/900 [==============================] - 54s - loss: 0.3283 - acc: 0.9548    \n",
      "Epoch 84/200\n",
      "900/900 [==============================] - 55s - loss: 0.3382 - acc: 0.9535    \n",
      "Epoch 85/200\n",
      "900/900 [==============================] - 54s - loss: 0.3392 - acc: 0.9537    \n",
      "Epoch 86/200\n",
      "900/900 [==============================] - 54s - loss: 0.3344 - acc: 0.9539    \n",
      "Epoch 87/200\n",
      "900/900 [==============================] - 54s - loss: 0.3334 - acc: 0.9537    \n",
      "Epoch 88/200\n",
      "900/900 [==============================] - 54s - loss: 0.3267 - acc: 0.9547    \n",
      "Epoch 89/200\n",
      "900/900 [==============================] - 55s - loss: 0.3230 - acc: 0.9549    \n",
      "Epoch 90/200\n",
      "900/900 [==============================] - 55s - loss: 0.3107 - acc: 0.9566    \n",
      "Epoch 91/200\n",
      "900/900 [==============================] - 54s - loss: 0.3042 - acc: 0.9577    \n",
      "Epoch 92/200\n",
      "900/900 [==============================] - 54s - loss: 0.3078 - acc: 0.9568    \n",
      "Epoch 93/200\n",
      "900/900 [==============================] - 54s - loss: 0.3165 - acc: 0.9553    \n",
      "Epoch 94/200\n",
      "900/900 [==============================] - 54s - loss: 0.3170 - acc: 0.9567    \n",
      "Epoch 95/200\n",
      "900/900 [==============================] - 59s - loss: 0.3177 - acc: 0.9570    \n",
      "Epoch 96/200\n",
      "900/900 [==============================] - 58s - loss: 0.3295 - acc: 0.9554    \n",
      "Epoch 97/200\n",
      "900/900 [==============================] - 55s - loss: 0.3169 - acc: 0.9571    \n",
      "Epoch 98/200\n",
      "900/900 [==============================] - 55s - loss: 0.2995 - acc: 0.9582    \n",
      "Epoch 99/200\n",
      "900/900 [==============================] - 55s - loss: 0.2930 - acc: 0.9589    \n",
      "Epoch 100/200\n",
      "900/900 [==============================] - 55s - loss: 0.2737 - acc: 0.9611    \n",
      "Epoch 101/200\n",
      "900/900 [==============================] - 54s - loss: 0.2727 - acc: 0.9613    \n",
      "Epoch 102/200\n",
      "900/900 [==============================] - 54s - loss: 0.2733 - acc: 0.9606    \n",
      "Epoch 103/200\n",
      "900/900 [==============================] - 54s - loss: 0.2724 - acc: 0.9606    \n",
      "Epoch 104/200\n",
      "900/900 [==============================] - 55s - loss: 0.2847 - acc: 0.9603    \n",
      "Epoch 105/200\n",
      "900/900 [==============================] - 55s - loss: 0.2860 - acc: 0.9609    \n",
      "Epoch 106/200\n",
      "900/900 [==============================] - 55s - loss: 0.2778 - acc: 0.9613    \n",
      "Epoch 107/200\n",
      "900/900 [==============================] - 54s - loss: 0.2666 - acc: 0.9616    \n",
      "Epoch 108/200\n",
      "900/900 [==============================] - 54s - loss: 0.2715 - acc: 0.9627    \n",
      "Epoch 109/200\n",
      "900/900 [==============================] - 56s - loss: 0.2577 - acc: 0.9635    \n",
      "Epoch 110/200\n",
      "900/900 [==============================] - 55s - loss: 0.2661 - acc: 0.9621    \n",
      "Epoch 111/200\n",
      "900/900 [==============================] - 55s - loss: 0.2640 - acc: 0.9619    \n",
      "Epoch 112/200\n",
      "900/900 [==============================] - 54s - loss: 0.2553 - acc: 0.9641    \n",
      "Epoch 113/200\n",
      "900/900 [==============================] - 57s - loss: 0.2566 - acc: 0.9636    \n",
      "Epoch 114/200\n",
      "900/900 [==============================] - 54s - loss: 0.2590 - acc: 0.9636    \n",
      "Epoch 115/200\n",
      "900/900 [==============================] - 54s - loss: 0.2736 - acc: 0.9621    \n",
      "Epoch 116/200\n",
      "900/900 [==============================] - 54s - loss: 0.2701 - acc: 0.9621    \n",
      "Epoch 117/200\n",
      "900/900 [==============================] - 54s - loss: 0.2680 - acc: 0.9621    \n",
      "Epoch 118/200\n",
      "900/900 [==============================] - 54s - loss: 0.2652 - acc: 0.9631    \n",
      "Epoch 119/200\n",
      "900/900 [==============================] - 54s - loss: 0.2673 - acc: 0.9629    \n",
      "Epoch 120/200\n",
      "900/900 [==============================] - 55s - loss: 0.2613 - acc: 0.9621    \n",
      "Epoch 121/200\n",
      "900/900 [==============================] - 54s - loss: 0.2675 - acc: 0.9618    \n",
      "Epoch 122/200\n",
      "900/900 [==============================] - 55s - loss: 0.2827 - acc: 0.9617    \n",
      "Epoch 123/200\n",
      "900/900 [==============================] - 55s - loss: 0.2761 - acc: 0.9621    \n",
      "Epoch 124/200\n",
      "900/900 [==============================] - 54s - loss: 0.2706 - acc: 0.9621    \n",
      "Epoch 125/200\n",
      "900/900 [==============================] - 55s - loss: 0.2712 - acc: 0.9622    \n",
      "Epoch 126/200\n",
      "900/900 [==============================] - 54s - loss: 0.2679 - acc: 0.9635    \n",
      "Epoch 127/200\n",
      "900/900 [==============================] - 54s - loss: 0.2762 - acc: 0.9626    \n",
      "Epoch 128/200\n",
      "900/900 [==============================] - 54s - loss: 0.2810 - acc: 0.9617    \n",
      "Epoch 129/200\n",
      "900/900 [==============================] - 54s - loss: 0.2802 - acc: 0.9622    \n",
      "Epoch 130/200\n",
      "900/900 [==============================] - 58s - loss: 0.2890 - acc: 0.9611    \n",
      "Epoch 131/200\n",
      "900/900 [==============================] - 55s - loss: 0.2825 - acc: 0.9622    \n",
      "Epoch 132/200\n",
      "900/900 [==============================] - 54s - loss: 0.2592 - acc: 0.9643    \n",
      "Epoch 133/200\n",
      "900/900 [==============================] - 54s - loss: 0.2568 - acc: 0.9632    \n",
      "Epoch 134/200\n",
      "900/900 [==============================] - 54s - loss: 0.2687 - acc: 0.9629    \n",
      "Epoch 135/200\n",
      "900/900 [==============================] - 55s - loss: 0.2545 - acc: 0.9638    \n",
      "Epoch 136/200\n",
      "900/900 [==============================] - 54s - loss: 0.2735 - acc: 0.9632    \n",
      "Epoch 137/200\n",
      "900/900 [==============================] - 55s - loss: 0.2637 - acc: 0.9641    \n",
      "Epoch 138/200\n",
      "900/900 [==============================] - 55s - loss: 0.2632 - acc: 0.9631    \n",
      "Epoch 139/200\n",
      "900/900 [==============================] - 54s - loss: 0.2528 - acc: 0.9652    \n",
      "Epoch 140/200\n",
      "900/900 [==============================] - 54s - loss: 0.2513 - acc: 0.9647    \n",
      "Epoch 141/200\n",
      "900/900 [==============================] - 54s - loss: 0.2623 - acc: 0.9627    \n",
      "Epoch 142/200\n",
      "900/900 [==============================] - 54s - loss: 0.2526 - acc: 0.9645    \n",
      "Epoch 143/200\n",
      "900/900 [==============================] - 54s - loss: 0.2484 - acc: 0.9647    \n",
      "Epoch 144/200\n",
      "900/900 [==============================] - 54s - loss: 0.2764 - acc: 0.9626    \n",
      "Epoch 145/200\n",
      "900/900 [==============================] - 54s - loss: 0.2613 - acc: 0.9635    \n",
      "Epoch 146/200\n",
      "900/900 [==============================] - 54s - loss: 0.2591 - acc: 0.9647    \n",
      "Epoch 147/200\n",
      "900/900 [==============================] - 54s - loss: 0.2560 - acc: 0.9646    \n",
      "Epoch 148/200\n",
      "900/900 [==============================] - 54s - loss: 0.2610 - acc: 0.9646    \n",
      "Epoch 149/200\n",
      "900/900 [==============================] - 54s - loss: 0.2438 - acc: 0.9655    \n",
      "Epoch 150/200\n",
      "900/900 [==============================] - 57s - loss: 0.2503 - acc: 0.9659    \n",
      "Epoch 151/200\n",
      "900/900 [==============================] - 54s - loss: 0.2417 - acc: 0.9659    \n",
      "Epoch 152/200\n",
      "900/900 [==============================] - 55s - loss: 0.2440 - acc: 0.9663    \n",
      "Epoch 153/200\n",
      "900/900 [==============================] - 54s - loss: 0.2361 - acc: 0.9672    \n",
      "Epoch 154/200\n",
      "900/900 [==============================] - 54s - loss: 0.2492 - acc: 0.9661    \n",
      "Epoch 155/200\n",
      "900/900 [==============================] - 54s - loss: 0.2612 - acc: 0.9651    \n",
      "Epoch 156/200\n",
      "900/900 [==============================] - 55s - loss: 0.2573 - acc: 0.9643    \n",
      "Epoch 157/200\n",
      "900/900 [==============================] - 55s - loss: 0.2841 - acc: 0.9622    \n",
      "Epoch 158/200\n",
      "900/900 [==============================] - 54s - loss: 0.2603 - acc: 0.9646    \n",
      "Epoch 159/200\n",
      "900/900 [==============================] - 54s - loss: 0.2557 - acc: 0.9636    \n",
      "Epoch 160/200\n",
      "900/900 [==============================] - 55s - loss: 0.2553 - acc: 0.9654    \n",
      "Epoch 161/200\n",
      "900/900 [==============================] - 54s - loss: 0.2514 - acc: 0.9656    \n",
      "Epoch 162/200\n",
      "900/900 [==============================] - 54s - loss: 0.2435 - acc: 0.9657    \n",
      "Epoch 163/200\n",
      "900/900 [==============================] - 54s - loss: 0.2489 - acc: 0.9657    \n",
      "Epoch 164/200\n",
      "900/900 [==============================] - 55s - loss: 0.2513 - acc: 0.9657    \n",
      "Epoch 165/200\n",
      "900/900 [==============================] - 54s - loss: 0.2553 - acc: 0.9663    \n",
      "Epoch 166/200\n",
      "900/900 [==============================] - 56s - loss: 0.2353 - acc: 0.9669    \n",
      "Epoch 167/200\n",
      "900/900 [==============================] - 54s - loss: 0.2408 - acc: 0.9669    \n",
      "Epoch 168/200\n",
      "900/900 [==============================] - 54s - loss: 0.2417 - acc: 0.9662    \n",
      "Epoch 169/200\n",
      "900/900 [==============================] - 56s - loss: 0.2373 - acc: 0.9664    \n",
      "Epoch 170/200\n",
      "900/900 [==============================] - 55s - loss: 0.2362 - acc: 0.9670    \n",
      "Epoch 171/200\n",
      "900/900 [==============================] - 54s - loss: 0.2382 - acc: 0.9669    \n",
      "Epoch 172/200\n",
      "900/900 [==============================] - 54s - loss: 0.2383 - acc: 0.9669    \n",
      "Epoch 173/200\n",
      "900/900 [==============================] - 57s - loss: 0.2469 - acc: 0.9659    \n",
      "Epoch 174/200\n",
      "900/900 [==============================] - 56s - loss: 0.2248 - acc: 0.9681    \n",
      "Epoch 175/200\n",
      "900/900 [==============================] - 55s - loss: 0.2405 - acc: 0.9669    \n",
      "Epoch 176/200\n",
      "900/900 [==============================] - 54s - loss: 0.2392 - acc: 0.9669    \n",
      "Epoch 177/200\n",
      "900/900 [==============================] - 54s - loss: 0.2345 - acc: 0.9670    \n",
      "Epoch 178/200\n",
      "900/900 [==============================] - 54s - loss: 0.2220 - acc: 0.9676    \n",
      "Epoch 179/200\n",
      "900/900 [==============================] - 54s - loss: 0.2152 - acc: 0.9682    \n",
      "Epoch 180/200\n",
      "900/900 [==============================] - 54s - loss: 0.2460 - acc: 0.9661    \n",
      "Epoch 181/200\n",
      "900/900 [==============================] - 54s - loss: 0.2375 - acc: 0.9669    \n",
      "Epoch 182/200\n",
      "900/900 [==============================] - 54s - loss: 0.2357 - acc: 0.9680    \n",
      "Epoch 183/200\n",
      "900/900 [==============================] - 54s - loss: 0.2300 - acc: 0.9679    \n",
      "Epoch 184/200\n",
      "900/900 [==============================] - 54s - loss: 0.2025 - acc: 0.9692    \n",
      "Epoch 185/200\n",
      "900/900 [==============================] - 56s - loss: 0.2191 - acc: 0.9689    \n",
      "Epoch 186/200\n",
      "900/900 [==============================] - 56s - loss: 0.2157 - acc: 0.9694    \n",
      "Epoch 187/200\n",
      "900/900 [==============================] - 54s - loss: 0.2090 - acc: 0.9692    \n",
      "Epoch 188/200\n",
      "900/900 [==============================] - 54s - loss: 0.2126 - acc: 0.9699    \n",
      "Epoch 189/200\n",
      "900/900 [==============================] - 54s - loss: 0.2177 - acc: 0.9686    \n",
      "Epoch 190/200\n",
      "900/900 [==============================] - 55s - loss: 0.2038 - acc: 0.9697    \n",
      "Epoch 191/200\n",
      "900/900 [==============================] - 56s - loss: 0.2105 - acc: 0.9698    \n",
      "Epoch 192/200\n",
      "900/900 [==============================] - 55s - loss: 0.2241 - acc: 0.9694    \n",
      "Epoch 193/200\n",
      "900/900 [==============================] - 54s - loss: 0.2313 - acc: 0.9685    \n",
      "Epoch 194/200\n",
      "900/900 [==============================] - 54s - loss: 0.1962 - acc: 0.9706    \n",
      "Epoch 195/200\n",
      "900/900 [==============================] - 54s - loss: 0.2051 - acc: 0.9702    \n",
      "Epoch 196/200\n",
      "900/900 [==============================] - 54s - loss: 0.2007 - acc: 0.9707    \n",
      "Epoch 197/200\n",
      "900/900 [==============================] - 54s - loss: 0.2090 - acc: 0.9708    \n",
      "Epoch 198/200\n",
      "900/900 [==============================] - 54s - loss: 0.1983 - acc: 0.9703    \n",
      "Epoch 199/200\n",
      "900/900 [==============================] - 54s - loss: 0.1952 - acc: 0.9706    \n",
      "Epoch 200/200\n",
      "900/900 [==============================] - 54s - loss: 0.2419 - acc: 0.9690    \n"
     ]
    }
   ],
   "source": [
    "#print(keras.__version__)\n",
    "#alphac = AlphaCallback()\n",
    "his = model.fit(x_train, y_train, batch_size=3, nb_epoch=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z_dim': 512, 'consume_less': 'cpu', 'ret_alpha': False, '_non_trainable_weights': [], 'dropout_Z': 0.3, 'd_regularizer': None, 'U_o': attentionlstm_1_U_o, 'regularizers': [<keras.regularizers.WeightRegularizer object at 0x000000001BE6A4E0>], 'W_regularizer': None, 'b2_att': attentionlstm_1_b2_att, 'dropout_U': 0.0, 'c_regularizer': None, 'forget_bias_init': <function one at 0x0000000009590EA0>, 'stateful': False, 'U': Join.0, 'Z_f': attentionlstm_1_Z_f, 'Wc_att': attentionlstm_1_Wc_att, 'c_f': attentionlstm_1_c_f, 'd_f': attentionlstm_1_d_f, 'uses_learning_phase': True, 'inner_init': <function orthogonal at 0x0000000009590D08>, 'Z': Join.0, 'b_i': attentionlstm_1_b_i, 'init': <function glorot_uniform at 0x0000000009590B70>, 'b_regularizer': None, 'W': Join.0, 'd_c': attentionlstm_1_d_c, 'U_i': attentionlstm_1_U_i, 'c_o': attentionlstm_1_c_o, 'Z_i': attentionlstm_1_Z_i, 'constraints': {}, 'd': Join.0, 'name': 'attentionlstm_1', 'outbound_nodes': [<keras.engine.topology.Node object at 0x000000002C109748>], 'go_backwards': False, 'Z_regularizer': <keras.regularizers.WeightRegularizer object at 0x000000001BE6A4E0>, 'b_f': attentionlstm_1_b_f, 'unroll': False, 'initial_z': input_2, 'built': True, 'inner_activation': <function hard_sigmoid at 0x00000000095906A8>, 'dropout_W': 0.0, 'b_o': attentionlstm_1_b_o, 'states': [Softmax.0, Softmax.0, Elemwise{add,no_inplace}.0, <TensorType(float32, matrix)>], 'input_spec': [<keras.engine.topology.InputSpec object at 0x000000001BE6A470>], 'U_regularizer': None, 'Z_o': attentionlstm_1_Z_o, 'inbound_nodes': [<keras.engine.topology.Node object at 0x000000002C122CC0>], 'initial_weights': None, 'output_dim': 512, 'b_c': attentionlstm_1_b_c, 'U_c': attentionlstm_1_U_c, 'supports_masking': True, 'initial_c': Softmax.0, 'initial_h': Softmax.0, 'W_i': attentionlstm_1_W_i, 'Wd_att': attentionlstm_1_Wd_att, 'activation': <function tanh at 0x0000000009590598>, 'trainable': True, 'input_dim': 512, 'U_f': attentionlstm_1_U_f, 'W_f': attentionlstm_1_W_f, 'W_c': attentionlstm_1_W_c, 'W_o': attentionlstm_1_W_o, 'b': Join.0, 'd_o': attentionlstm_1_d_o, 'd_i': attentionlstm_1_d_i, 'U_att': attentionlstm_1_U_att, 'c_c': attentionlstm_1_c_c, 'return_sequences': True, 'alphaz': Softmax.0, 'Z_c': attentionlstm_1_Z_c, 'input_length': None, '_trainable_weights': [attentionlstm_1_Wc_att, attentionlstm_1_Wd_att, attentionlstm_1_U_att, attentionlstm_1_b_att, attentionlstm_1_b2_att, attentionlstm_1_W_i, attentionlstm_1_U_i, attentionlstm_1_Z_i, attentionlstm_1_b_i, attentionlstm_1_c_i, attentionlstm_1_d_i, attentionlstm_1_W_c, attentionlstm_1_U_c, attentionlstm_1_Z_c, attentionlstm_1_b_c, attentionlstm_1_c_c, attentionlstm_1_d_c, attentionlstm_1_W_f, attentionlstm_1_U_f, attentionlstm_1_Z_f, attentionlstm_1_b_f, attentionlstm_1_c_f, attentionlstm_1_d_f, attentionlstm_1_W_o, attentionlstm_1_U_o, attentionlstm_1_Z_o, attentionlstm_1_b_o, attentionlstm_1_c_o, attentionlstm_1_d_o], 'c': Join.0, 'b_att': attentionlstm_1_b_att, 'c_i': attentionlstm_1_c_i}\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[6].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shapes [(None, 44, 512), (None, 512), (None, 512), (None, 196, 512)]\n"
     ]
    }
   ],
   "source": [
    "aLstm_AlphaLayer = AttentionLSTM( ret_alpha=True, output_dim=WORD_DIM, z_dim=ANNOTATION_DIM, W_regularizer=l2(0.01), U_regularizer=l2(0.01), Z_regularizer=l2(0.01), dropout_W=0.3, dropout_U=0.3, dropout_Z=0.3, return_sequences=True, weights=model.layers[6].get_weights())\n",
    "aLstm_Alpha = aLstm_AlphaLayer([xt_dense, h_Dense, c_Dense, z_inp])\n",
    "model2 = Model(input=[x_inp, z_inp, z_mean], output=aLstm_Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pre = model2.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 44, 196)\n"
     ]
    }
   ],
   "source": [
    "print(y_pre.shape)\n",
    "with open('results/alphab.pkl', 'wb') as f:\n",
    "    pkl.dump(y_pre, f, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev_h1 = K.dot(z_mean, h_Dense_l.W) + h_Dense_l.b\n",
    "proj_z = K.dot(z_inp, aLstm_Layer.Wc_att) + aLstm_Layer.b_att\n",
    "proj_state = K.dot(prev_h1, aLstm_Layer.Wd_att)\n",
    "proj_z = proj_z + proj_state[:, None, :]\n",
    "proj_z = K.tanh(proj_z)\n",
    "\n",
    "alpha = K.dot(proj_z, aLstm_Layer.U_att ) + aLstm_Layer.b2_att\n",
    "alpha_shape = alpha.shape\n",
    "alpha = K.softmax(alpha.reshape((alpha_shape[0], alpha_shape[1])))\n",
    "\n",
    "f_alpha = K.function([z_inp, z_mean], alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#alpha = f_alpha([ann_vec_train, z_mean_train])\n",
    "#print(type(ins))\n",
    "#al = alpha_func(x_train)\n",
    "#print(al.shape)\n",
    "#print(al)\n",
    "with open('results/alpha.pkl', 'wb') as f:\n",
    "    pkl.dump(alpha, f, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuCAReduce{add}{0,0,1}.0, <CudaNdarrayType(float32, matrix)>)\nToposort index: 118\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(3, 196), (1, 196)]\nInputs strides: [(196, 1), (0, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{0,x,1,x}(GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{44}, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{tanh,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, attentionlstm_1_U_o, attentionlstm_1_Z_o, attentionlstm_1_U_f, attentionlstm_1_Z_f, attentionlstm_1_U_i, attentionlstm_1_Z_i, attentionlstm_1_U_c, attentionlstm_1_Z_c, GpuFromHost.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, MakeVector{dtype='int64'}.0, MakeVector{dtype='int64'}.0, attentionlstm_1_U_att, GpuDimShuffle{1,0}.0)\nToposort index: 325\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, (True, True, False)), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, vector), TensorType(int64, vector), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(), (44, 3, 196, 512), (44, 3, 512), (44, 3, 512), (44, 3, 2048), (44, 1, 196), (44, 3, 196, 512), (44, 3, 512), (44, 3, 2048), (44, 3, 512), (44, 3, 512), (45, 3, 512), (45, 3, 512), (45, 3, 196, 512), (45, 1, 196), (2, 512), (2, 512, 1), (2, 1), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (), (), (), (), (), (), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (3, 196, 512), (1, 512), (512, 512), (3, 512), (1, 1, 1), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (512, 512), (2,), (1,), (512, 1), (1, 512)]\nInputs strides: [(), (-301056, 100352, 512, 1), (-1536, 512, 1), (1536, 512, 1), (6144, 2048, 1), (196, 0, 1), (301056, 100352, 512, 1), (1536, 512, 1), (-2048, 90112, 1), (-1536, 512, 1), (-512, 22528, 1), (1536, 512, 1), (1536, 512, 1), (301056, 100352, 512, 1), (196, 0, 1), (512, 1), (512, 1, 0), (1, 0), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (), (), (), (), (), (), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (100352, 512, 1), (0, 1), (1, 512), (512, 1), (0, 0, 0), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (1, 512), (8,), (8,), (1, 0), (0, 1)]\nInputs values: [array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[ 0.]\\n [ 0.]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[[ 0.]]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array([512,   1], dtype=int64), array([1], dtype=int64), 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.0, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.1, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.2, Constant{44}, Constant{43}, Constant{-1})], [], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.4, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.5, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.6, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.7, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.8, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.9, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.10, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.11, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.12, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.13, Constant{1})], [GpuSubtensor{::int64}(forall_inplace,gpu,grad_of_scan_fn}.14, Constant{-1})], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.15)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.16, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.17)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.18, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.19)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.20, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.21)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.22, MakeVector{dtype='int64'}.0)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.23, MakeVector{dtype='int64'}.0), Shape_i{1}(forall_inplace,gpu,grad_of_scan_fn}.23), Shape_i{2}(forall_inplace,gpu,grad_of_scan_fn}.23)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    954\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    943\u001b[0m                                          \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                                          self, node)\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4316)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuCAReduce{add}{0,0,1}.0, <CudaNdarrayType(float32, matrix)>)\nToposort index: 118\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(3, 196), (1, 196)]\nInputs strides: [(196, 1), (0, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{0,x,1,x}(GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f5c6dd8673d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    953\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    954\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    942\u001b[0m                                          \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                                          \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                                          self, node)\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4316)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\WinPython-64bit-3.4.4.4Qt5\\python-3.4.4.amd64\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (C:\\Users\\panka\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_94_Stepping_3_GenuineIntel-3.4.4-64\\scan_perform\\mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: GpuElemwise. Input dimension mis-match. Input 1 (indices start at 0) has shape[0] == 1, but the output's size on that axis is 3.\nApply node that caused the error: GpuElemwise{Add}[(0, 0)](GpuCAReduce{add}{0,0,1}.0, <CudaNdarrayType(float32, matrix)>)\nToposort index: 118\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(3, 196), (1, 196)]\nInputs strides: [(196, 1), (0, 1)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuDimShuffle{0,x,1,x}(GpuElemwise{Add}[(0, 0)].0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: forall_inplace,gpu,grad_of_scan_fn}(TensorConstant{44}, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuElemwise{tanh,no_inplace}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuElemwise{Composite{(i0 - sqr(i1))},no_inplace}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuSubtensor{int64:int64:int64}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, GpuAlloc{memset_0=True}.0, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, TensorConstant{44}, attentionlstm_1_U_o, attentionlstm_1_Z_o, attentionlstm_1_U_f, attentionlstm_1_Z_f, attentionlstm_1_U_i, attentionlstm_1_Z_i, attentionlstm_1_U_c, attentionlstm_1_Z_c, GpuFromHost.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,x,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuSubtensor{int64}.0, GpuDimShuffle{x,0}.0, GpuDimShuffle{1,0}.0, GpuDimShuffle{1,0}.0, MakeVector{dtype='int64'}.0, MakeVector{dtype='int64'}.0, attentionlstm_1_U_att, GpuDimShuffle{1,0}.0)\nToposort index: 325\nInputs types: [TensorType(int64, scalar), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, 4D), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), TensorType(int64, scalar), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, 3D), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, (True, True, False)), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, row), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix), TensorType(int64, vector), TensorType(int64, vector), CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(), (44, 3, 196, 512), (44, 3, 512), (44, 3, 512), (44, 3, 2048), (44, 1, 196), (44, 3, 196, 512), (44, 3, 512), (44, 3, 2048), (44, 3, 512), (44, 3, 512), (45, 3, 512), (45, 3, 512), (45, 3, 196, 512), (45, 1, 196), (2, 512), (2, 512, 1), (2, 1), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (2, 512), (), (), (), (), (), (), (), (), (), (), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (512, 512), (3, 196, 512), (1, 512), (512, 512), (3, 512), (1, 1, 1), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (1, 512), (512, 512), (3, 512), (1, 512), (512, 512), (512, 512), (2,), (1,), (512, 1), (1, 512)]\nInputs strides: [(), (-301056, 100352, 512, 1), (-1536, 512, 1), (1536, 512, 1), (6144, 2048, 1), (196, 0, 1), (301056, 100352, 512, 1), (1536, 512, 1), (-2048, 90112, 1), (-1536, 512, 1), (-512, 22528, 1), (1536, 512, 1), (1536, 512, 1), (301056, 100352, 512, 1), (196, 0, 1), (512, 1), (512, 1, 0), (1, 0), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (), (), (), (), (), (), (), (), (), (), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (512, 1), (100352, 512, 1), (0, 1), (1, 512), (512, 1), (0, 0, 0), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (0, 1), (1, 512), (512, 1), (0, 1), (1, 512), (1, 512), (8,), (8,), (1, 0), (0, 1)]\nInputs values: [array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[ 0.]\\n [ 0.]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), array(44, dtype=int64), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', b'CudaNdarray([[[ 0.]]])', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', array([512,   1], dtype=int64), array([1], dtype=int64), 'not shown', 'not shown']\nOutputs clients: [[GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.0, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.1, Constant{44}, Constant{43}, Constant{-1})], [GpuSubtensor{int64:int64:int64}(forall_inplace,gpu,grad_of_scan_fn}.2, Constant{44}, Constant{43}, Constant{-1})], [], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.4, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.5, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.6, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.7, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.8, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.9, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.10, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.11, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.12, Constant{1})], [GpuSubtensor{int64}(forall_inplace,gpu,grad_of_scan_fn}.13, Constant{1})], [GpuSubtensor{::int64}(forall_inplace,gpu,grad_of_scan_fn}.14, Constant{-1})], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.15)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.16, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.17)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.18, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.19)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.20, MakeVector{dtype='int64'}.0)], [GpuDimShuffle{1,0,2}(forall_inplace,gpu,grad_of_scan_fn}.21)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.22, MakeVector{dtype='int64'}.0)], [GpuReshape{2}(forall_inplace,gpu,grad_of_scan_fn}.23, MakeVector{dtype='int64'}.0), Shape_i{1}(forall_inplace,gpu,grad_of_scan_fn}.23), Shape_i{2}(forall_inplace,gpu,grad_of_scan_fn}.23)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=3, nb_epoch=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s     \n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(x_test, y_test, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9598917388916015, 0.63886363700032234]\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 37s    \n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict(x_train, batch_size=3, verbose=1)\n",
    "y_pred_test = model.predict(x_train, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(y_pred.shape)\n",
    "\n",
    "def gen_captions(y_p):\n",
    "    sentences = []\n",
    "    for y_i in y_p:\n",
    "        sentence = \"\"\n",
    "        for word_v in y_i:\n",
    "            max_i = np.argmax(word_v, axis = -1)\n",
    "            word = index_to_word[max_i]\n",
    "            if word == '#END#' or word == '#NULL#':\n",
    "                break\n",
    "            sentence = sentence + word + \" \"\n",
    "        #print(sentence)\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Two young guys with shaggy hair look at their hands while hanging out in the yard ', 'Several men in hard hats are operating a giant pulley system ', 'A child in a pink dress is climbing up a set of stairs in an entry way ', 'Someone in a blue shirt and hat is standing on stair and leaning against a window ', 'Two men one in a gray shirt one in a black shirt standing near a stove ', 'Two people in the photo are playing the guitar and the other is poking at him ', 'A man sits in a chair while holding a large stuffed animal of a lion ', 'A girl is on rollerskates talking on her cellphone standing in a parking lot ', 'An asian man wearing a black suit stands near a darkhaired woman and a brownhaired woman ', 'Two men in Germany jumping over a rail at the same time without shirts ', 'Five ballet dancers caught mid jump in a dancing studio with sunlight coming through a window ', 'Three young men and a young woman wearing sneakers are leaping in midair at the top of a flight of concrete stairs ', 'A black dog and a white dog with brown spots are staring at each other in the street ', 'A man with reflective safety clothes and ear protection drives a John Deere tractor on a road ', 'Some women are standing in front of a bus with buildings behind it ', 'A young woman with dark hair and wearing glasses is putting white powder on a cake using a sifter ', 'A small girl in the grass plays with fingerpaints in front of a white canvas with a rainbow on it ', 'A man sleeping on a bench outside with a white and black dog sitting next to him ', 'A group of adults inside a home sitting on chairs arranged in a circle playing a type of musical instruments ', 'Two women both wearing glasses are playing clarinets and an elderly woman is playing a stringed instrument ', 'A person in gray stands alone on a structure outdoors in the dark ', 'A man in a white tshirt looks toward the camera surrounded by a crowd near a metro station ', 'A man with a goatee in a black shirt and white latex gloves is using a tattoo gun to place a tattoo on someones back ', 'Two children a girl and a boy are practicing their writing ', 'A man in a blue hard hat and orange safety vest stands in an intersection while holding a flag ', 'A person with long gray hair has a beret with beige and white wearing a blue raincoat is painting a marketplace scenery surrounded by other artists and paintings ', 'A man stands on one foot while holding on to a waste basket ', 'A small child grips onto the red ropes at the playground ', 'Young man in jacket holding a toothpick with something on the end of it ', 'Young blond man in a blue and yellow jacket smiling while standing in front of a net ', 'A man with a baseball cap and black jacket stands in a bathroom while holding a coffee mug ', 'Five people walking with a multicolored sky in the background ', 'A man with black hair sits in a restaurant with a glass of beer ', 'An officer in a reflective vest stands at the front of his van with his dog ', 'The white out conditions of snow on the ground seem to almost obliverate the details of a man dressed for the cold weather in a heavy jacket and red hat riding a bicycle in a suburban neighborhood ', 'Five men uniformly dressed in white shirts tie and black slacks converse at the back of an open van ', 'A tan man with a backwards hat looks at the camera while walking through a factory ', 'A caucasian man wearing a shortsleeved black shirt and a darkskinned woman wearing a sleeveless dress are working at a conveyor ', 'Man wearing a blue and white outfit holding a broom with a traditional Asian architecture in the background ', 'Two men in florescent vests are standing next to parked cars in front of a small building while one of them converses with a driver and a woman on a bike is seen riding by ', 'A little girl in a pink shirt and a little girl in an orange shirt sitting in the grass ', 'A person in tan pants is inside a silver mobile object while people watch ', 'A man in black approaches a strange silver object containing a person while many onlookers observe from behind a roped off barrier ', 'Bride and groom walking side by side out of focus on pathway next to brick building ', 'A little boy plays with a Nintendo GameCube controller inside a McDonalds ', 'White dog with brown ears standing near water with head turned to one side ', 'A group of people picnicking at picnic tables in front of a playground ', 'Two asian or spanish people a woman and a man sitting together in front of a glass window as cars pass ', 'Women are seated at a picnic table eating while a man in a white tshirt and a yellow and orange balloon design on his head stands in the background ', 'Two people are demonstrating martial arts to a crowd and jumping over three youngsters who are crouched on the mat ']\n"
     ]
    }
   ],
   "source": [
    "gts_sentences = gen_captions(gts)\n",
    "gts_train = gts_sentences[0:900]\n",
    "gts_test = gts_sentences[900:]\n",
    "\n",
    "def create_json_dict(s_train):\n",
    "    s_d = []\n",
    "    for i, sent in enumerate(s_train):\n",
    "        dict_cap = {}\n",
    "        dict_cap[\"image_id\"] = i\n",
    "        dict_cap[\"caption\"] = sent\n",
    "        s_d.append(dict_cap)\n",
    "    return s_d\n",
    "\n",
    "train_d = create_json_dict(gts_train)\n",
    "test_d = create_json_dict(gts_test)\n",
    "print(gts_train[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%s %s (11, 'Three young men and a young woman wearing sneakers are leaping in midair at the top of a flight of concrete stairs ')\n",
      "%s %s (605, 'A dog leaps into the air in a grassy field surrounded by trees ')\n",
      "%s %s (791, 'A dog takes a leap of faith as he jumps into a pool to grab an orange toy ')\n",
      "%s %s (860, 'A goggled boy leaps from the edge into a shimmering pool with someone watching on in the background ')\n"
     ]
    }
   ],
   "source": [
    "string = \"The man wearing white clothes and white leg padding is practicing a sport\"\n",
    "for i, gts_str in enumerate(gts_sentences):\n",
    "    if \"leap\" in gts_str:\n",
    "        print(\"%s %s\", (i, gts_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two young guys with shaggy hair look at their hands while hanging out in the yard \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#train_full = create_json_dict(gts_sentences)\n",
    "pred_sent_full = gen_captions(y_pred_test)\n",
    "#pred_full = create_json_dict(pred_sent_full)\n",
    "\n",
    "with open('results/attn_pred.txt', 'w') as f:\n",
    "    f.writelines(pred_sent_full)\n",
    "'''    \n",
    "with open('results/attn_ref.json', 'w') as f:\n",
    "    json.dump(train_full, f)\n",
    "'''\n",
    "print(pred_sent_full[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899\n",
      "899\n",
      "899\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "pred_sentence = []\n",
    "pred_sentence = gen_captions(y_pred)\n",
    "pred_d = create_json_dict(pred_sentence)\n",
    "print(len(pred_sentence))\n",
    "print(len(pred_d))\n",
    "print(len(y_pred))\n",
    "\n",
    "pred_test_sentence = []\n",
    "pred_test_sentence = gen_captions(y_pred_test)\n",
    "pred_d_test = create_json_dict(pred_test_sentence)\n",
    "print(len(pred_test_sentence))\n",
    "print(len(pred_d_test))\n",
    "print(len(y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train, batch_size=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('results/ref_train.json', 'w') as f:\n",
    "    json.dump(train_d, f)\n",
    "\n",
    "with open('results/ref_test.json', 'w') as f:\n",
    "    json.dump(test_d, f)\n",
    "\n",
    "with open('results/pred_train.json', 'w') as f:\n",
    "    json.dump(pred_d, f)\n",
    "\n",
    "with open('results/pred_test.json', 'w') as f:\n",
    "    json.dump(pred_d_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = []\n",
    "with open('results/VGG16_LTSM_1k.pkl', 'rb') as f: \n",
    "    j = pkl.load(f, encoding='latin1')\n",
    "\n",
    "def gen_json_dict_from_pkl(pkl_list):\n",
    "    pred_list = []\n",
    "    ref_list = []\n",
    "    for i, pkl_dict in enumerate(pkl_list):\n",
    "        dict_cap = {}\n",
    "        dict_cap ['image_id'] = i\n",
    "        dict_cap['caption'] = pkl_dict['predictions'][0]\n",
    "        pred_list.append(dict_cap)\n",
    "        dict_ref = {}\n",
    "        dict_ref['image_id'] = i\n",
    "        dict_ref['caption'] = pkl_dict['labels'][0]\n",
    "        ref_list.append(dict_ref)\n",
    "    return pred_list, ref_list\n",
    "\n",
    "gnet_pred, gnet_ref = gen_json_dict_from_pkl(j)\n",
    "with open('results/VGG16_LTSM_1k_pred.json', 'w') as f:\n",
    "    json.dump(gnet_pred, f)\n",
    "\n",
    "with open('results/VGG16_LTSM_1k_ref.json', 'w') as f:\n",
    "    json.dump(gnet_ref, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_processing(dataset):\n",
    "    allwords = Counter()\n",
    "    for item in dataset:\n",
    "        for sentence in item['sentences']:\n",
    "            allwords.update(sentence['tokens'])\n",
    "            \n",
    "    vocab = [k for k, v in allwords.items()]\n",
    "    vocab.insert(0, '<NULL>')\n",
    "    vocab.append('<START>')\n",
    "    vocab.append('<END>')\n",
    "    vocab.append('<UNK>')\n",
    "\n",
    "    word_to_index = {w: i for i, w in enumerate(vocab)}\n",
    "    index_to_word = {i: w for i, w in enumerate(vocab)}\n",
    "    return vocab, word_to_index, index_to_word\n",
    "\n",
    "def import_flickr8kdataset():\n",
    "    dataset = json.load(open('captions/dataset_flickr8k.json'))['images']\n",
    "    #reduced length to a 300 for testing\n",
    "    val_set = list(filter(lambda x: x['split'] == 'val', dataset))\n",
    "    train_set = list(filter(lambda x: x['split'] == 'train', dataset))\n",
    "    test_set = list(filter(lambda x: x['split'] == 'test', dataset))\n",
    "    return train_set[:800]+val_set[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def floatX(arr):\n",
    "    return np.asarray(arr, dtype=theano.config.floatX)\n",
    "\n",
    "#Prep Image uses an skimage transform\n",
    "def prep_image(im):\n",
    "    if len(im.shape) == 2:\n",
    "        im = im[:, :, np.newaxis]\n",
    "        im = np.repeat(im, 3, axis=2)\n",
    "    # Resize so smallest dim = 224, preserving aspect ratio\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (224, w*224/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*224/w, 224), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    \n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "\n",
    "    im = im - MEAN_VALUES\n",
    "    return rawim, floatX(im[np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language_model():\n",
    "    model = Sequential()\n",
    "    print('Adding Embedding')\n",
    "    model.add(Embedding(VOCAB_COUNT, EMBEDDING_SIZE, input_length=SEQUENCE_LENGTH-1))\n",
    "    print('Adding LSTM')\n",
    "    model.add(LSTM(EMBEDDING_SIZE, return_sequences=False))\n",
    "    #print('Adding TimeDistributed Dense')\n",
    "    #model.add(TimeDistributed(Dense(EMBEDDING_SIZE)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = import_flickr8kdataset()\n",
    "# Currently testing it out\n",
    "dataset = [i for i in dataset[:100]]\n",
    "vocab,word_to_index, index_to_word = word_processing(dataset)\n",
    "#print vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def process_images(dataset, coco=False, d_set=\"Flicker8k_Dataset\"):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    cnn_input = floatX(np.zeros((len(dataset), 3, 224, 224)))\n",
    "    rawim_input = []\n",
    "    sentences_tokens = []\n",
    "    for i, image in enumerate(dataset):\n",
    "        print \"ind_process %s total %s\" %(str(ind_process),str(total))\n",
    "        ind_process+=1\n",
    "        if coco:\n",
    "            fn = './coco/{}/{}'.format(image['filepath'], image['filename'])\n",
    "        else:\n",
    "            fn = d_set+'/{}'.format(image['filename'])\n",
    "        try:\n",
    "            im = plt.imread(fn)\n",
    "            rawim, cnn_input[i] = prep_image(im)\n",
    "            sentences_tokens.append(image['sentences'][0]['tokens'])\n",
    "            rawim_input.append(rawim)\n",
    "        except IOError:\n",
    "            continue\n",
    "    return rawim_input, cnn_input, sentences_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rawim_array, cnnim_array, sentences_tokens = process_images(dataset, coco=False, d_set=\"Flicker8k_Dataset\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_image_partial_captions(images, captions, word_to_index, vocab_count, model):\n",
    "    a_images = []\n",
    "    a_captions = []\n",
    "    next_words = []\n",
    "    #vocab_size = len(vocab)\n",
    "    for ind, image in enumerate(images):\n",
    "        sentence = captions[ind]\n",
    "        partial_caption_ar = np.zeros(SEQUENCE_LENGTH-1, dtype=np.int)\n",
    "        \n",
    "        words = ['<START>'] + sentence + ['<END>']\n",
    "        assert len(words)<SEQUENCE_LENGTH\n",
    "        for i in range(len(words) - 1):\n",
    "            pc_copy = partial_caption_ar.copy()\n",
    "            if words[i] in word_to_index:\n",
    "                pc_copy[i] = word_to_index[words[i]]\n",
    "            else:\n",
    "                pc_copy[i] = word_to_index[\"<UNK>\"]\n",
    "            a_images.append(image)\n",
    "            a_captions.append(pc_copy)\n",
    "            #Generate next word output vector\n",
    "            next_word = words[i + 1]\n",
    "            if next_word in word_to_index:\n",
    "                next_word_index = word_to_index[next_word]\n",
    "            else:\n",
    "                next_word_index = word_to_index[\"<UNK>\"]\n",
    "            next_word_ar = np.zeros(vocab_count, dtype=np.int)\n",
    "            next_word_ar[next_word_index] = 1\n",
    "            next_words.append(next_word_ar)\n",
    "    v_i = np.array(a_images)\n",
    "    v_c = np.array(a_captions)\n",
    "    v_nw = np.array(next_words)\n",
    "    return v_i, v_c, v_nw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vocab_count = len(word_to_index)\n",
    "#print cnnim_array.shape\n",
    "#v_i, v_c, v_nw = gen_image_partial_captions(cnnim_array, sentences_tokens, word_to_index, vocab_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_COUNT = len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def process_cnn_features(dataset, model, coco=False, d_set=\"Flicker8k_Dataset\"):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    for chunk in chunks(dataset, 25):\n",
    "        cnn_input = floatX(np.zeros((len(chunk), 3, 224, 224)))\n",
    "        for i, image in enumerate(chunk):\n",
    "            print \"ind_process %s total %s\" %(str(ind_process),str(total))\n",
    "            ind_process+=1\n",
    "            if coco:\n",
    "                fn = './coco/{}/{}'.format(image['filepath'], image['filename'])\n",
    "            else:\n",
    "                fn = d_set+'/{}'.format(image['filename'])\n",
    "            try:\n",
    "                im = plt.imread(fn)\n",
    "                _, cnn_input[i] = prep_image(im)\n",
    "            except IOError:\n",
    "                continue\n",
    "        features = model.predict(cnn_input)\n",
    "        print \"Processing Features For Chunk\"\n",
    "        for i, image in enumerate(chunk):\n",
    "            image['cnn features'] = features[i]\n",
    "            \n",
    "def process_captions_array(dataset):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    for chunk in chunks(dataset, 25):\n",
    "        for i in chunk:\n",
    "            \n",
    "            image[\"captions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VGG_16('weights/vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, images, index_to_word, word_to_index):\n",
    "    for image in images:\n",
    "        caption = np.zeros(SEQUENCE_LENGTH - 1).reshape(1, SEQUENCE_LENGTH - 1)\n",
    "        print(caption.shape)\n",
    "        caption[0,0] = word_to_index[\"<START>\"]\n",
    "        count=0\n",
    "        sentence = []\n",
    "        a = image.reshape(1,3,224,224)\n",
    "        #a = np.array([image])\n",
    "        while True:\n",
    "            out = model.predict([a, caption])\n",
    "            index = out.argmax(-1)\n",
    "            index = index[0]\n",
    "            word = index_to_word[index]\n",
    "            sentence.append(word)\n",
    "            count+= 1\n",
    "            if count >= SEQUENCE_LENGTH - 1 or index == word_to_index[\"<END>\"]: #max caption length reach of '<eos>' encountered\n",
    "                break\n",
    "            caption[0,count] = index\n",
    "        sent_str = \" \".join(sentence)\n",
    "        print(\"The Oracle says : %s\" %sent_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnnim_list = []\n",
    "for i in cnnim_array:\n",
    "    cnnim_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict(model, cnnim_list, index_to_word, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caption = np.zeros(SEQUENCE_LENGTH).reshape(1, SEQUENCE_LENGTH)\n",
    "caption[0] = word_to_index[\"#START#\"]\n",
    "print cnnim_array[0].shape\n",
    "t = np.array(cnnim_array[0])\n",
    "print t.shape\n",
    "out = model.predict([v_i, v_c])\n",
    "print out\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
