{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D \n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import GRU, TimeDistributed, RepeatVector, Merge, TimeDistributedDense\n",
    "import h5py\n",
    "import text_processor_utils as tp_utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import theano\n",
    "from keras.preprocessing import sequence\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import image_classes as img_class\n",
    "import json\n",
    "from collections import Counter\n",
    "import random\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform\n",
    "\n",
    "MEAN_VALUES = np.array([104, 117, 123]).reshape((3,1,1))\n",
    "SEQUENCE_LENGTH = 32\n",
    "MAX_SENTENCE_LENGTH = SEQUENCE_LENGTH - 3 # 1 for image, 1 for start token, 1 for end token\n",
    "BATCH_SIZE = 20\n",
    "CNN_FEATURE_SIZE = 1000\n",
    "EMBEDDING_SIZE = 256\n",
    "\n",
    "def word_processing(dataset):\n",
    "    allwords = Counter()\n",
    "    for item in dataset:\n",
    "        for sentence in item['sentences']:\n",
    "            allwords.update(sentence['tokens'])\n",
    "            \n",
    "    vocab = [k for k, v in allwords.items() if v >= 5]\n",
    "    vocab.insert(0, '#START#')\n",
    "    vocab.append('#END#')\n",
    "\n",
    "    word_to_index = {w: i for i, w in enumerate(vocab)}\n",
    "    index_to_word = {i: w for i, w in enumerate(vocab)}\n",
    "    return vocab, word_to_index, index_to_word\n",
    "\n",
    "def import_flickr8kdataset():\n",
    "    dataset = json.load(open('captions/dataset_flickr8k.json'))['images']\n",
    "    #reduced length to a 300 for testing\n",
    "    val_set = list(filter(lambda x: x['split'] == 'val', dataset))\n",
    "    train_set = list(filter(lambda x: x['split'] == 'train', dataset))\n",
    "    test_set = list(filter(lambda x: x['split'] == 'test', dataset))\n",
    "    return train_set[:800]+val_set[:200]\n",
    "    \n",
    "\n",
    "def pop(model):\n",
    "    '''Removes a layer instance on top of the layer stack.\n",
    "    This code is thanks to @joelthchao https://github.com/fchollet/keras/issues/2371#issuecomment-211734276\n",
    "    '''\n",
    "    if not model.outputs:\n",
    "        raise Exception('Sequential model cannot be popped: model is empty.')\n",
    "    else:\n",
    "        model.layers.pop()\n",
    "        if not model.layers:\n",
    "            model.outputs = []\n",
    "            model.inbound_nodes = []\n",
    "            model.outbound_nodes = []\n",
    "        else:\n",
    "            model.layers[-1].outbound_nodes = []\n",
    "            model.outputs = [model.layers[-1].output]\n",
    "        model.built = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def floatX(arr):\n",
    "    return np.asarray(arr, dtype=theano.config.floatX)\n",
    "\n",
    "#Prep Image uses an skimage transform\n",
    "def prep_image(im):\n",
    "    if len(im.shape) == 2:\n",
    "        im = im[:, :, np.newaxis]\n",
    "        im = np.repeat(im, 3, axis=2)\n",
    "    # Resize so smallest dim = 224, preserving aspect ratio\n",
    "    h, w, _ = im.shape\n",
    "    if h < w:\n",
    "        im = skimage.transform.resize(im, (224, w*224/h), preserve_range=True)\n",
    "    else:\n",
    "        im = skimage.transform.resize(im, (h*224/w, 224), preserve_range=True)\n",
    "\n",
    "    # Central crop to 224x224\n",
    "    h, w, _ = im.shape\n",
    "    im = im[h//2-112:h//2+112, w//2-112:w//2+112]\n",
    "    \n",
    "    rawim = np.copy(im).astype('uint8')\n",
    "    \n",
    "    # Shuffle axes to c01\n",
    "    im = np.swapaxes(np.swapaxes(im, 1, 2), 0, 1)\n",
    "    \n",
    "    # Convert to BGR\n",
    "    im = im[::-1, :, :]\n",
    "\n",
    "    im = im - MEAN_VALUES\n",
    "    return rawim, floatX(im[np.newaxis])\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "def process_cnn_features(dataset, model, coco=False, d_set=\"Flicker8k_Dataset\"):\n",
    "    ind_process = 1\n",
    "    total = len(dataset)\n",
    "    for chunk in chunks(dataset, 25):\n",
    "        cnn_input = floatX(np.zeros((len(chunk), 3, 224, 224)))\n",
    "        for i, image in enumerate(chunk):\n",
    "            print \"ind_process %s total %s\" %(str(ind_process),str(total))\n",
    "            ind_process+=1\n",
    "            if coco:\n",
    "                fn = './coco/{}/{}'.format(image['filepath'], image['filename'])\n",
    "            else:\n",
    "                fn = d_set+'/{}'.format(image['filename'])\n",
    "            try:\n",
    "                im = plt.imread(fn)\n",
    "                _, cnn_input[i] = prep_image(im)\n",
    "            except IOError:\n",
    "                continue\n",
    "        features = model.predict(cnn_input)\n",
    "        print \"Processing Features For Chunk\"\n",
    "        for i, image in enumerate(chunk):\n",
    "            image['cnn features'] = features[i]\n",
    "\n",
    "def get_data_batch(dataset, size, split='train'):\n",
    "    items = []\n",
    "    \n",
    "    while len(items) < size:\n",
    "        item = random.choice(dataset)\n",
    "        if item['split'] != split:\n",
    "            continue\n",
    "        sentence = random.choice(item['sentences'])['tokens']\n",
    "        if len(sentence) > MAX_SENTENCE_LENGTH:\n",
    "            continue\n",
    "        items.append((item['cnn features'], sentence, item['filename']))\n",
    "    \n",
    "    return items\n",
    "\n",
    "def calc_cross_ent(net_output, mask, targets):\n",
    "    # Helper function to calculate the cross entropy error\n",
    "    preds = T.reshape(net_output, (-1, len(vocab)))\n",
    "    targets = T.flatten(targets)\n",
    "    cost = T.nnet.categorical_crossentropy(preds, targets)[T.flatten(mask).nonzero()]\n",
    "    return cost\n",
    "\n",
    "\n",
    "# Convert a list of tuples into arrays that can be fed into the network\n",
    "def prep_batch_for_network(batch,word_to_index):\n",
    "    x_cnn = floatX(np.zeros((len(batch), 1000)))\n",
    "    x_sentence = np.zeros((len(batch), SEQUENCE_LENGTH - 1), dtype='int32')\n",
    "    y_sentence = np.zeros((len(batch), SEQUENCE_LENGTH), dtype='int32')\n",
    "    mask = np.zeros((len(batch), SEQUENCE_LENGTH), dtype='bool')\n",
    "\n",
    "    for j, (cnn_features, sentence, _) in enumerate(batch):\n",
    "        x_cnn[j] = cnn_features\n",
    "        i = 0\n",
    "        for word in ['#START#'] + sentence + ['#END#']:\n",
    "            if word in word_to_index:\n",
    "                mask[j, i] = True\n",
    "                y_sentence[j, i] = word_to_index[word]\n",
    "                x_sentence[j, i] = word_to_index[word]\n",
    "                i += 1\n",
    "        #mask[j, 0] = False\n",
    "                \n",
    "    return x_cnn, x_sentence, y_sentence, mask\n",
    "\n",
    "def predict(x_cnn):\n",
    "    x_sentence = np.zeros((BATCH_SIZE, SEQUENCE_LENGTH - 1), dtype='int32')\n",
    "    words = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        p0 = f(x_cnn, x_sentence)\n",
    "        pa = p0.argmax(-1)\n",
    "        tok = pa[0][i]\n",
    "        word = index_to_word[tok]\n",
    "        if word == '#END#' or i >= SEQUENCE_LENGTH - 1:\n",
    "            return ' '.join(words)\n",
    "        else:\n",
    "            x_sentence[0][i] = tok\n",
    "            if word != '#START#':\n",
    "                words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielsampetethiyagu/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/Users/danielsampetethiyagu/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/Users/danielsampetethiyagu/anaconda/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    }
   ],
   "source": [
    "model = VGG_16('weights/vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dataset = pickle.load(open(\"flickr8k_200_with_cnn_features.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366\n"
     ]
    }
   ],
   "source": [
    "vocab,wrd_to_ind, ind_to_wrd = word_processing(dataset)\n",
    "SEQUENCE_LENGTH = 32\n",
    "MAX_SENTENCE_LENGTH = SEQUENCE_LENGTH - 3 # 1 for image, 1 for start token, 1 for end token\n",
    "BATCH_SIZE = 20\n",
    "CNN_FEATURE_SIZE = 1000\n",
    "EMBEDDING_SIZE = 256\n",
    "print len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0535f90288ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(3, 256, 256))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
